{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"float:right; max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Scénarios d'Apprentissage Statistique](https://github.com/wikistat/Apprentissage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Adaptation Statistique d'un Modèle de Prévision du Pic d'Ozone avec <a href=\"https://cran.r-project.org/\"><img src=\"https://cran.r-project.org/Rlogo.svg\" style=\"max-width: 40px; display: inline\" alt=\"R\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résumé**: \n",
    "- Exploration puis modélisation de données climatiques en utilisant R. \n",
    "- L'objectif est de prévoir pour le lendemain un possible dépassement d'un seuil de concentration en ozone à partir d'une prévision déterministe sur un maillage grossier et de variables climatiques locales. \n",
    "- Estimation par différentes méthodes : régression [linéaire](http://wikistat.fr/pdf/st-m-app-select.pdf) ou   [logistique](http://wikistat.fr/pdf/st-m-app-rlogit.pdf), [analyse discriminante](http://wikistat.fr/pdf/st-m-app-add.pdf), [arbre de décision](http://wikistat.fr/pdf/st-m-app-cart.pdf), [réseau de neurones](http://wikistat.fr/pdf/st-m-app-rn.pdf), [agrégation de modèle](http://wikistat.fr/pdf/st-m-app-agreg.pdf), [SVM](http://wikistat.fr/pdf/st-m-app-svm.pdf). \n",
    "- Comparaison des [erreurs de prévision](http://wikistat.fr/pdf/st-m-app-risque.pdf) sur un échantillon test puis des courbes ROC. \n",
    "- Industrialisation avec le package `caret` et itération sur plusieurs échantillons tests pour analyser la distribution de l'erreur de prévision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avertissement** \n",
    "\n",
    "* Ce tutoriel est découpé en séances / épisodes de travaux dirigés synchronisées avec le cours d'apprentissage machine. \n",
    "* Réfléchir aux réponses aux questions marquées **Question**.\n",
    "* Ce calepin est complété par celui en Python (à faire _après_, ou en parallèle) afin de comparer les performances respectives des deux environnements.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif, sur ces données, est d'améliorer la prévision déterministe (MOCAGE), calculée par les services de MétéoFrance,  de la concentration d'ozone dans certaines stations de prélèvement.  Il s'agit d'un problème dit d'*adaptation statistique* d'une prévision locale de modèles à trop grande échelle en s'aidant d'autres variables également gérées par MétéoFrance, mais à plus petite échelle (température, force du vent...). C'est une première façon de concevoir de l'*IA hybride* entre un modèle déterministe et un algorithme d'apprentissage automatique. Plus précisément, deux variables peuvent être prévues : soit la concentration quantitative d'ozone, soit le dépassement (qualitatif) d'un certain seuil fixé à 150 $\\mu g$. Dans chaque cas, deux approches sont considérées : soit prévoir la *concentration quantitative* puis en déduire l'éventuel dépassement ou bien prévoir directement le *dépassement*. Dans le premier cas, il s'agit d'abord d'une *régression* tandis que dans le deuxième il s'agit d'un problème de *discrimination* à deux classes ou de régression logistique. \n",
    "\n",
    "La question posée est donc: quelles sont les meilleures méthodes et stratégies pour prévoir la concentration d'ozone du lendemain d'une part et l'occurrence d'un pic de pollution d'autre part.\n",
    "\n",
    "On se propose de tester différentes méthodes : régression [logistique](http://wikistat.fr/pdf/st-m-app-rlogit.pdf), [analyse discriminante](http://wikistat.fr/pdf/st-m-app-add.pdf), [réseau de neurones](http://wikistat.fr/pdf/st-m-app-rn.pdf), [arbre de décision](http://wikistat.fr/pdf/st-m-app-cart.pdf), [agrégation d'arbres](http://wikistat.fr/pdf/st-m-app-agreg.pdf) (bagging, boosting, random forest), [SVM](http://wikistat.fr/pdf/st-m-app-svm.pdf).  L'objectif final, à ne pas perdre de vue, est la comparaison de ces méthodes afin de déterminer la plus efficace pour répondre au problème de prévision. Ceci passe par la mise en place d'un protocole très strict afin de s'assurer d'un minimum d'objectivité pour cette comparaison.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toutes les opérations sont réalisées dans R avec l'appui de bibliothèques complémentaires éventuellement à télécharger : \n",
    "* Episode 1 : ggplot2, tidyverse, gridExtra, corrplot, FactoMineR, factoextra, glmnet, ggfortify, pROC, \n",
    "* Pour les autres épisodes : mlbench, MASS, boot, class, e1071, rpart, partykit, nnet, ipred, gbm, randomForest, caret, doParallel, xgboost, missForest, Rlof, dbscan, kernlab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python (consulter le [calepin](https://github.com/wikistat/Apprentissage/blob/master/Pic-ozone/Apprent-Python-Ozone.ipynb)) conduit à des résultats comparables mais moins complets pour leur interprétation. En particulier, l'absence du type *DataFrame* dans la librairie scikit-learn n'autorise pas une sélection fine des variables dans les modèles statistiques usuels. En revanche, l'exécution de la validation croisée Monte Carlo est plus rapide en python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <FONT COLOR=\"Red\">Épisode 1 : Statistiques descriptives et modèles linéaires</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des librairies nécessaires\n",
    "library(ggplot2)\n",
    "library(tidyverse)\n",
    "library(gridExtra)\n",
    "library(GGally)\n",
    "library(plotly)\n",
    "library(corrplot)\n",
    "library(reshape2)\n",
    "library(FactoMineR) \n",
    "library(factoextra)\n",
    "library(glmnet) \n",
    "library(ggfortify)\n",
    "library(pROC)\n",
    "library(ROCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prise en charge des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données ont été extraites et mises en forme par le service concerné de Météo France. Elles sont décrites par les variables suivantes :\n",
    "\n",
    "* **JOUR** : type de jour ; férié (1) ou pas (0) ;\n",
    "* **O3obs** : concentration d'ozone effectivement observée le lendemain à 17h locales correspondant souvent au maximum de pollution observée ;\n",
    "* **MOCAGE** : prévision de cette pollution obtenue par un modèle déterministe de mécanique des fluides (équation de Navier et Stockes);\n",
    "* **TEMPE** : température prévue par MétéoFrance pour le lendemain 17h ;\n",
    "* **RMH2O** : rapport d'humidité ;\n",
    "* **NO2** : concentration en dioxyde d'azote ;\n",
    "* **NO** : concentration en monoxyde d'azote ;\n",
    "* **STATION** : lieu de l'observation : Aix-en-Provence, Rambouillet, Munchhausen, Cadarache et Plan de Cuques ;\n",
    "* **VentMOD** : force du vent ;\n",
    "* **VentANG** : orientation du vent. \n",
    "\n",
    "Ce sont des données \"propres\", sans trous, bien codées et de petites tailles. Elles présentent donc avant tout un caractère pédagogique car permettant de décliner puis comparer toutes les approches de régression et classification supervisée.\n",
    "\n",
    "**Attention**: Même si les données sont de qualité, une étude exploratoire préalable est toujours nécessaire pour se familiariser avec les données et les préparer à la phase de modélisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T09:48:06.646161Z",
     "start_time": "2019-11-22T09:48:06.591Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lecture des données\n",
    "# path=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/data/\"\n",
    "path <- \"\"\n",
    "ozone <- read.table(paste(path, \"depSeuil.dat\", sep = \"\"),\n",
    "                    sep = \",\", header = TRUE)\n",
    "# Premières lignes du jeu de données\n",
    "head(ozone)\n",
    "# Vérification du contenu\n",
    "summary(ozone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:37.832339Z",
     "start_time": "2019-11-18T09:21:59.889Z"
    }
   },
   "outputs": [],
   "source": [
    "# Changement du type des variables qualitatives en facteur\n",
    "ozone[, \"JOUR\"] <- as.factor(ozone[, \"JOUR\"])\n",
    "ozone[, \"STATION\"] <- as.factor(ozone[, \"STATION\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification dans le summary\n",
    "summary(ozone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration élémentaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistiques unidimensionnelles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Précisez la nature des différentes variables. \n",
    "Il est nécessaire d'en étudier la distribution. \n",
    "Notez la symétrie ou non de celles-ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(gridExtra)\n",
    "g1<-ggplot(ozone,aes(x=O3obs))+\n",
    "  geom_histogram(aes(y=after_stat(density)))+\n",
    "  geom_density(alpha=.2, col=\"blue\") \n",
    "g2<-ggplot(ozone,aes(x=NO2))+\n",
    "  geom_histogram(aes(y=..density..))+\n",
    "  geom_density(alpha=.2, col=\"blue\") \n",
    "\n",
    "grid.arrange(g1,g2,ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Même chose pour les autres variables\n",
    "g3<-ggplot(ozone,aes(x=MOCAGE))+geom_histogram(aes(y=..density..))+geom_density(alpha=.2, col=\"blue\") \n",
    "g4<-ggplot(ozone,aes(x=TEMPE))+geom_histogram(aes(y=..density..))+geom_density(alpha=.2, col=\"blue\") \n",
    "g5<-ggplot(ozone,aes(x=RMH2O))+geom_histogram(aes(y=..density..))+geom_density(alpha=.2, col=\"blue\") \n",
    "g6<-ggplot(ozone,aes(x=NO))+geom_histogram(aes(y=..density..))+geom_density(alpha=.2, col=\"blue\") \n",
    "g7<-ggplot(ozone,aes(x=VentMOD))+geom_histogram(aes(y=..density..))+geom_density(alpha=.2, col=\"blue\") \n",
    "g8<-ggplot(ozone,aes(x=VentANG))+geom_histogram(aes(y=..density..))+geom_density(alpha=.2, col=\"blue\") \n",
    "\n",
    "grid.arrange(g3,g4,g5,g6,g7,g8,ncol=3)\n",
    "rm(g1,g2,g3,g4,g5,g6,g7,g8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Des transformations sont proposées pour rendre certaines distributions plus symétriques et ainsi plus \"gaussiennes\". C'est nécessaire pour certaines méthodes à venir de modélisation (linéaires), pas pour toutes (arbres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ozone[, \"SRMH2O\"] <- sqrt(ozone[, \"RMH2O\"])\n",
    "ozone[, \"LNO2\"] <- log(ozone[, \"NO2\"])\n",
    "ozone[, \"LNO\"] <- log(ozone[, \"NO\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Vérifiez l'opportunité de ces transformations puis retirez les variables initiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ozone <- ozone[, c(1:4, 8:13)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On construit maintenant la variable de dépassement de seuil `DepSeuil` pour obtenir le fichier qui sera effectivement utilisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ozone[, \"DepSeuil\"] <- as.factor(ozone[, \"O3obs\"] > 150)\n",
    "summary(ozone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrélations des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Que dire sur les relations des variables 2 à 2 ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggpairs(ozone[, c(2:4, 6:10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Complétez en visualisant les corrélations avec la fonction `corrplot()` (package `corrplot`). Quelle est la limite de ce type de diagnostic numérique : quel type de corrélation est mesuré ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "library(corrplot)\n",
    "corrplot(cor(ozone[, c(2:4, 6:10)]),method=\"ellipse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse en composantes principales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les commandes suivantes permettent de réaliser une [analyse en composantes principales](http://wikistat.fr/pdf/st-m-explo-acp.pdf) (ACP) sur les seules variables quantitatives. Par ailleurs la variable à modéliser (O3obs, concentration observée) n'est pas utilisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACP réduite\n",
    "library(FactoMineR)\n",
    "acp <- PCA(ozone[, c(11,2:4, 6:10)], scale.unit = TRUE,\n",
    "           graph = FALSE, quali.sup = 1, quanti.sup = 2, ncp = 7)\n",
    "# Décroissance des valeurs propres\n",
    "library(factoextra)\n",
    "g1<-fviz_eig(acp, addlabels = TRUE, ylim = c(0, 40))\n",
    "library(reshape2)\n",
    "g2<-ggplot(melt(acp$ind$coord),aes(x=Var2,y=value))+\n",
    "  geom_boxplot()+\n",
    "  xlab(\"\")\n",
    "grid.arrange(g1,g2,ncol=2)\n",
    "# \n",
    "library(corrplot)\n",
    "corrplot(acp$var$cor, is.corr=FALSE,method=\"ellipse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fviz_pca_var(acp)\n",
    "fviz_pca_ind(acp,col.ind=\"contrib\",label=\"none\",gradient.cols = c(\"white\", \"#2E9FDF\", \"#FC4E07\" ))\n",
    "fviz_pca_var(acp,axes=c(1,3))\n",
    "fviz_pca_ind(acp,col.ind=\"contrib\",label=\"none\",gradient.cols = c(\"white\", \"#2E9FDF\", \"#FC4E07\" ),axes=c(1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Que représentent ces différents graphiques?\n",
    "\n",
    "**Question** Que dire du choix du nombre de dimensions, des valeurs atypiques?\n",
    "\n",
    "**Question** Que dire de la structure de corrélation des variables ? Est-elle intuitive ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même graphe en coloriant selon le dépassement de seuil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fviz_pca_ind(acp, label=\"none\", habillage=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif est donc de définir une surface séparant les deux classes. \n",
    "\n",
    "**Question** Une discrimination linéaire (hyperplan) semble-t-elle possible ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce n'est pas utile ici mais une classification non supervisée est facile à obtenir. Par exemple en 2 classes, par l'algorithme des K-means. Donne-t-elle la même information ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.ozone <- kmeans(ozone[, c(3:4, 6:10)], centers = 2)\n",
    "# Représentation dans les coordonnées de l'acp\n",
    "acp2 <- PCA(cbind(clus = as.factor(km.ozone$cluster),\n",
    "          ozone[, c(11, 3:4, 6:10)]), scale.unit = TRUE,\n",
    "          graph = FALSE, quali.sup = 1:2, ncp = 7)\n",
    "fviz_pca_ind(acp2, label=\"none\", habillage=\"clus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protocole de comparaison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratégie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La recherche  d'une meilleure méthode de prévision suit le protocole suivant.\n",
    "\n",
    "1. Étapes descriptives préliminaires uni- et multidimensionnelle visant à repérer les incohérences, les variables non significatives ou de distribution exotique, les individus non concernés ou atypiques... et à étudier les structures des données. Ce peut être aussi la longue étape de construction de variables, attributs ou *features* spécifiques des données. \n",
    "2. Procéder à un tirage aléatoire d'un échantillon *test* qui ne sera utilisé que lors de la *dernière étape* de comparaison des méthodes.\n",
    "3. La partie restante est l'échantillon d'*apprentissage* pour l'estimation des paramètres des modèles.\n",
    "4. Pour chacune des méthodes, optimiser la complexité des modèles en minimisant une estimation \"sans biais\" de l'erreur de prévision, par exemple par [*validation croisée*](http://wikistat.fr/pdf/st-m-app-risque-estim.pdf):\n",
    "    - Variables et interactions à prendre en compte dans la régression linéaire ou logistique;\n",
    "    - variables et méthode pour l'analyse discriminante;\n",
    "    - nombre de feuilles dans l'arbre de régression ou de classification;\n",
    "    - architecture (nombre de neurones, pénalisation) du perceptron;\n",
    "    - algorithme d'agrégation, \n",
    "    - noyau et pénalisation des SVMs.\n",
    "5.  Comparaison des qualités de prévision sur la base du taux de mal classés pour le seul échantillon test qui est resté à l'écart de tout effort ou \"acharnement\" pour l'optimisation des modèles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En cas d'échantillon relativement \"petit\" il est recommandé d'itérer la procédure de découpage apprentissage / test, afin de réduire la variance (moyenne) des estimations des erreurs de prévision.\n",
    "\n",
    "**Question** Comment appelle-t-on cette procédure spécifique de validation croisée ?\n",
    "\n",
    "* *Attention* : ne pas \"tricher\" en modifiant le modèle obtenu lors de l'étape précédente afin d'améliorer le résultat sur l'échantillon test!\n",
    "* Le critère utilisé dépend du problème : erreur quadratique, taux de mauvais classement, entropie, AUC (aire sous la courbe ROC), indice de Pierce, *log loss function*..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des échantillons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les commandes ci-dessous réalisent l'extraction du sous-ensemble des données d'apprentissage et de test. \n",
    "\n",
    "Utilisez trois chiffres au hasard, et **remplacez** \"111\" ci-dessous, comme initialisation du générateur de nombres aléatoires. Attention, chaque participant tire un échantillon différent ; il est donc \"normal\" de ne pas obtenir les mêmes modèles, les mêmes résultats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:39.945357Z",
     "start_time": "2019-11-18T09:22:02.486Z"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(111) # initialisation du générateur\n",
    "# Extraction des échantillons\n",
    "test.ratio <- .2   # part de l'échantillon test\n",
    "npop <- nrow(ozone) # nombre de lignes dans les données\n",
    "nvar <- ncol(ozone) # nombre de colonnes\n",
    "# taille de l'échantillon test\n",
    "ntest <- ceiling(npop * test.ratio) \n",
    "# indices de l'échantillon test\n",
    "testi <- sample(1:npop, ntest)\n",
    "# indices de l'échantillon d'apprentissage\n",
    "appri <- setdiff(1:npop, testi) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction des échantillons pour la régression: prévision de la concentration en ozone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:39.976151Z",
     "start_time": "2019-11-18T09:22:02.695Z"
    }
   },
   "outputs": [],
   "source": [
    "# construction de l'échantillon d'apprentissage\n",
    "datappr <- ozone[appri, -11] \n",
    "# construction de l'échantillon test\n",
    "datestr <- ozone[testi, -11] \n",
    "# vérification\n",
    "str(datappr)\n",
    "str(datestr)\n",
    "#summary(datappr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction des échantillons pour la discrimination: prévision de dépassement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:40.000864Z",
     "start_time": "2019-11-18T09:22:02.905Z"
    }
   },
   "outputs": [],
   "source": [
    "# construction de l'échantillon d'apprentissage\n",
    "datappq <- ozone[appri,-2]\n",
    "# construction de l'échantillon test \n",
    "datestq <- ozone[testi,-2] \n",
    "\n",
    "# vérification\n",
    "str(datappq)\n",
    "str(datestq)\n",
    "#summary(datappq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque** : Nous avons ici \"manuellement\" fait la construction des échantillons à des fins pédagogiques. En pratique, on peut utiliser des fonctions de R qui font ce travail, en particulier la fonction `createDataPartition` de la librairie `caret`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, avant de passer aux différents algorithmes, définissons une fonction traçant le graphe des résidus avec des couleurs et des échelles fixes sur les axes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gplot.res <- function(x, y, titre = \"titre\"){\n",
    "    ggplot(data.frame(x=x, y=y),aes(x,y))+\n",
    "    geom_point(col = \"blue\")+xlim(0, 250)+ylim(-150, 150)+\n",
    "    ylab(\"Résidus\")+ xlab(\"Valeurs prédites\")+\n",
    "    ggtitle(titre)+\n",
    "    geom_hline(yintercept = 0,col=\"green\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Prévision par modèle linéaire Gaussien](http://wikistat.fr/pdf/st-m-app-select.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le premier modèle à tester est un simple modèle linéaire Gaussien mais, comme certaines variables sont qualitatives, il s'agit d'une analyse de covariance. D'autre part, on s'intéresse à savoir si des interactions sont à prendre en compte. Le modèle devient alors polynomial d'ordre 2 ou quadratique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sans sélection de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle linéaire intégre ici des variables qualitatives; c'est dans ce cas une *analyse de covariance*  estimée par la fonction `aov` mieux adaptée à ce modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:40.107560Z",
     "start_time": "2019-11-18T09:22:03.699Z"
    }
   },
   "outputs": [],
   "source": [
    "# estimation du modèle sans interaction\n",
    "reg.lm <-aov(O3obs ~ . , data = datappr)\n",
    "# Extraction des résidus et des valeurs ajustées de ce modèle\n",
    "res.lm <- reg.lm$residuals\n",
    "fit.lm <- reg.lm$fitted.values\n",
    "# Graphe des résidus. \n",
    "gplot.res(fit.lm,res.lm,\"ANCOVA sans sélection de variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Que dire de la distribution de ces résidus ? \n",
    "\n",
    "**Question** La forme du nuage renseigne sur les hypothèses de linéarité du modèle et d'homoscédasticité. Que dire de la validité de ce modèle ?\n",
    "\n",
    "Appréciez néanmoins sa significativité par la commande suivante.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:40.123527Z",
     "start_time": "2019-11-18T09:22:03.902Z"
    }
   },
   "outputs": [],
   "source": [
    "summary(reg.lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef(reg.lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Ce premier modèle est comparé avec celui de la seule prévision déterministe MOCAGE. Qu'en conclure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:40.226000Z",
     "start_time": "2019-11-18T09:22:04.102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Graphe des résidus du modèle déterministe MOCAGE\n",
    "g1<-gplot.res(datappr[, \"MOCAGE\"],datappr[, \"O3obs\"]-datappr[, \"MOCAGE\"], \"linéaire, MOCAGE seul\")\n",
    "\n",
    "g2<-gplot.res(fit.lm, res.lm, \"Linéaire, sans sélection\")\n",
    "grid.arrange(g1,g2,ncol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sélection de variable par régularisation L1 (LASSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(glmnet)\n",
    "# avec des variables quantitatives seulement\n",
    "reg.lasso.quanti <- glmnet(y = datappr[, 2],\n",
    "                           x = as.matrix(datappr[, -c(1, 2, 5)]))\n",
    "# avec toutes les variables, créer d'abord la matrice d'expériences \n",
    "# avec 'model.matrix' (penser à retirer l'intercept du modèle)\n",
    "x.mat <- model.matrix(O3obs ~ . - 1, data = datappr)\n",
    "reg.lasso <- glmnet(y = datappr$O3obs, x = x.mat)\n",
    "options(repr.plot.width = 12, repr.plot.height = 10)\n",
    "plot(reg.lasso, xvar = \"lambda\", label = TRUE)\n",
    "legend(\"topright\", \n",
    "       legend = paste(1:ncol(x.mat), \" - \", colnames(x.mat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Que fait la commande model.matrix ? Comment sont gérées les variables catégorielles ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(model.matrix)\n",
    "head(x.mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Que représentent les courbes ci-dessus, appelées \"chemins de régularisation\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On s'intéresse ensuite au choix du paramètre de régularisation par validation croisée: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.lasso.cv <- cv.glmnet(y = datappr[, 2], x = x.mat)\n",
    "#plot(reg.lasso.cv)\n",
    "autoplot(reg.lasso.cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(glmnet)\n",
    "help(cv.glmnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Que représente les points gras ? Et la bande qui est autour ? \n",
    "\n",
    "**Question** Comment sont obtenues les valeurs de log(lambda) correspondant aux lignes verticales en pointillé ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valeur estimée\n",
    "paste(\"CV estimate of lambda :\", round(reg.lasso.cv$lambda.1se, 3))\n",
    "# modèle correspondant\n",
    "coef(reg.lasso.cv, s = \"lambda.1se\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Combien restent-ils de coefficients non nuls. Vérifiez sur les chemins de régularisation.\n",
    "\n",
    "**Question** Même question en choisissant l'autre valeur de lambda retenue par glmnet, i.e. `reg.lasso.cv$lambda.min`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(reg.lasso, xvar = \"lambda\", label = TRUE,xlim=c(0,2),ylim=c(-2,5))\n",
    "abline(v=log(reg.lasso.cv$lambda.1se),col=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valeur estimée\n",
    "paste(\"CV estimate of lambda :\", round(reg.lasso.cv$lambda.min, 3))\n",
    "# modèle correspondant\n",
    "coef(reg.lasso.cv, s = \"lambda.min\")\n",
    "\n",
    "plot(reg.lasso, xvar = \"lambda\", label = TRUE,xlim=c(-2,0),ylim=c(-5,40))\n",
    "abline(v=log(reg.lasso.cv$lambda.min),col=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On trace ensuite les résidus en fonction des valeurs prédites. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des valeurs ajustées et des résidus\n",
    "\n",
    "fit.lasso <- predict(reg.lasso.cv, s = \"lambda.min\", newx = x.mat)\n",
    "res.lasso <- datappr$O3obs - fit.lasso\n",
    "\n",
    "fit.lasso.1se <- predict(reg.lasso.cv, s = \"lambda.1se\", newx = x.mat)\n",
    "res.lasso.1se <- datappr$O3obs - fit.lasso.1se \n",
    "\n",
    "# Graphe des résidus\n",
    "options(repr.plot.width = 12, repr.plot.height = 4)\n",
    "par(mfrow = c(1, 3))\n",
    "gplot.res(fit.lm, res.lm, \"Linéaire, sans sélection\")\n",
    "gplot.res(fit.lasso, res.lasso, \"Linéaire, pénalité L1, lambda min\")\n",
    "gplot.res(fit.lasso.1se, res.lasso.1se, \"Linéaire, pénalité L1, lambda 1se\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Commentez. \n",
    "\n",
    "**Question** Calculez le critère MSE (moyenne des carrés des résidus) pour les deux modèles. Pourquoi celui obtenu par LASSO est-il moins bon ? Quel critère LASSO minimise t-il ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paste(\"Modèle linéaire sans sélection:\",mean(res.lm^2))\n",
    "paste(\"LASSO avec lambda.min:\",mean(res.lasso^2))\n",
    "paste(\"LASSO avec lambda.1se:\",mean(res.lasso.1se^2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Estimez l'erreur du modèle linéaire simple sans sélection de variables par validation croisée. Comparez avec celle du LASSO. Qu'observez-vous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V=10 ; nV=floor(nrow(datappr)/V)\n",
    "S=sample(1:nrow(datappr),replace=FALSE)\n",
    "error.CV = c()\n",
    "for(v in 1:V)\n",
    "{ # Rq : les deux dernières obs sont tjs dans l'échantillon d'apprentissage...\n",
    "    datappr.learn=datappr[-c(S[(nV*(v-1)):(nV*v)]),] \n",
    "    datappr.valid=datappr[c(S[(nV*(v-1)):(nV*v)]),]\n",
    "    error.CV=c(error.CV,mean((datappr.valid$O3obs-predict(aov(O3obs ~ ., data=datappr.learn),newdata=datappr.valid))^2))\n",
    "}\n",
    "mean(error.CV)\n",
    "\n",
    "print(reg.lasso.cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle quadratique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'étude suivante met en oeuvre toutes les interactions d'ordre 2 entre les variables. Il s'agit donc d'un modèle de régression quadratique. Il est estimé avec la fonction `glm()` qui permet une sélection automatique de modèle. La méthode descendante est utilisée mais celle pas-à-pas pourrait également l'être. Ce type de procédure n'est pas implémentée en python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sélection de variables par critère AIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sélection descendante: à chaque étape, chaque modèle est comparé à tous les sous-modèles possibles obtenus par suppression d'une des interactions ou une des variables, à condition qu'elle ne soit pas présente dans une interaction. La variable sélectionnée et supprimée est celle qui fait décroîre le critère considéré : AIC (*Akaïke Information Criterion*). \n",
    "\n",
    "**Question** Quel autre critère, équivalent à AIC dans le cas gaussien et de variance résiduelle connue, est utilisé en régression linéaire ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:44.291201Z",
     "start_time": "2019-11-18T09:22:04.508Z"
    }
   },
   "outputs": [],
   "source": [
    "# Estimation du modèle avec toutes les interactions d'ordre 2\n",
    "reg.glm <- glm(O3obs ~ .^2, data = datappr)\n",
    "# Recherche du meilleur modèle au sens \n",
    "# du critère d'Akaïke par méthode descendante\n",
    "reg.glm.step <- step(reg.glm, direction = \"backward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:44.497378Z",
     "start_time": "2019-11-18T09:22:04.515Z"
    }
   },
   "outputs": [],
   "source": [
    "# Coefficients du modèle\n",
    "anova(reg.glm.step, test = \"F\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sélection de variable par régularisation L1 (LASSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer avec un modèle quadratique avec pénalité L1\n",
    "x.mat2 <- model.matrix(O3obs ~ .^2 - 1, data = datappr)\n",
    "reg.lasso2.cv <- cv.glmnet(y = datappr[, \"O3obs\"], x = x.mat2)\n",
    "coef(reg.lasso2.cv, s = \"lambda.1se\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:44.635351Z",
     "start_time": "2019-11-18T09:22:04.520Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extraction des valeurs ajustées et des résidus\n",
    "fit.glm <- reg.glm.step$fitted.values\n",
    "res.glm <- reg.glm.step$residuals\n",
    "fit.lasso2 <- predict(reg.lasso2.cv, s = \"lambda.min\", newx = x.mat2)\n",
    "res.lasso2 <- datappr$O3obs - fit.lasso2\n",
    "\n",
    "# Graphe des résidus\n",
    "g1<-gplot.res(fit.lm, res.lm, \"linéaire\")\n",
    "g2<-gplot.res(fit.lasso, res.lasso, \"linéaire, pénalité L1\")\n",
    "g3<-gplot.res(fit.glm, res.glm, \"quadratique, backward AIC\")\n",
    "g4<-gplot.res(fit.lasso2, res.lasso2, \"quadratique, pénalité L1\")\n",
    "grid.arrange(g1,g2,g3,g4,ncol=2,nrow=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " On remarque que la présence de certaines interactions ou variables sont pertinentes au sens du critère d'Akaïke mais pas significative au sens du test de Fisher. Cette présence dans le modèle pourrait être plus finement analysée en considérant une estimation de l'erreur par validation croisée. L'idée serait de retirer une à une les variables ou interactions les moins significatives pour voir comment se comporte la validation croisée. D'autre part, si la procédure pas-à-pas conduit à un modèle différent, l'estimation de l'erreur par validation croisée permet également d'optimiser le choix.\n",
    " \n",
    "Ces raffinements ne s'avèrent pas efficaces sur ces données. Le modèle obtenu par minimisaiton du critère AIC est conservé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prévision de l'échantillon test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle \"optimal\" obtenu par la méthode descendante est utilisé pour prédire l'échantillon test et estimer ainsi, sans biais, une erreur de prévision. Deux erreurs sont estimées : la première est celle quadratique pour la régression tandis que la deuxième est issue de la matrice de confusion qui croise les dépassements de seuils prédits avec ceux effectivement observés. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erreur de régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:44.652288Z",
     "start_time": "2019-11-18T09:22:05.132Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calcul des prévisions pour le modèle quadratique backward AIC\n",
    "pred.glm <- predict(reg.glm.step, newdata = datestr)\n",
    "# Erreur quadratique moyenne de prévision (MSE)\n",
    "sum((pred.glm - datestr[, \"O3obs\"])^2) / nrow(datestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:44.669514Z",
     "start_time": "2019-11-18T09:22:05.139Z"
    }
   },
   "outputs": [],
   "source": [
    "# Erreur quadratique par MOCAGE\n",
    "sum((datestr[,\"MOCAGE\"] - datestr[,\"O3obs\"])^2) / nrow(datestr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erreur de classification (matrice de confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:44.689237Z",
     "start_time": "2019-11-18T09:22:05.144Z"
    }
   },
   "outputs": [],
   "source": [
    "# Matrice de confusion pour la prévision du dépassement de seuil\n",
    "table(pred.glm > 150, datestr[, \"O3obs\"] > 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:44.714261Z",
     "start_time": "2019-11-18T09:22:05.150Z"
    }
   },
   "outputs": [],
   "source": [
    "# Matrice de confusion pour la prévision du \n",
    "# dépassement de seuil par MOCAGE\n",
    "table(datestr[, \"MOCAGE\"] > 150, datestr[, \"O3obs\"] > 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noter ces erreurs pour les comparer avec celles obtenues par les autres méthodes. Noter l'asymétrie des erreurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Prévision par modèle binomial](http://wikistat.fr/pdf/st-m-app-rlogit.pdf)\n",
    "\n",
    "Plutôt que de prévoir la concentration puis le dépassement, on peut se poser la question de savoir s'il ne serait pas pertinent de prévoir directement la présence ou l'absence d'un dépassement. La variable à modéliser étant binaire, c'est la régression logistique qui va être employée. Comme pour la régression, différentes stratégies de choix de modèle peuvent être utilisées et comparées avant d'estimer l'erreur de prévision sur l'échantillon test.\n",
    "\n",
    "### Régression logistique sans interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:44.819132Z",
     "start_time": "2019-11-18T09:22:05.557Z"
    }
   },
   "outputs": [],
   "source": [
    "# estimation du modèle complet\n",
    "log.lm <- glm(DepSeuil ~. , data = datappq, family = binomial)\n",
    "# significativité des paramètres\n",
    "anova(log.lm, test = \"Chisq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:45.012876Z",
     "start_time": "2019-11-18T09:22:05.564Z"
    }
   },
   "outputs": [],
   "source": [
    "# Recherche d'un modèle optimal au sens d'Akaïke\n",
    "log.lm.step <- step(log.lm, direction = \"backward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:45.052862Z",
     "start_time": "2019-11-18T09:22:05.570Z"
    }
   },
   "outputs": [],
   "source": [
    "# Modèle obtenu\n",
    "anova(log.lm.step, test = \"Chisq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:45.074743Z",
     "start_time": "2019-11-18T09:22:05.576Z"
    }
   },
   "outputs": [],
   "source": [
    "# matrice de confusion de l'échantillon d'apprentissage et erreur apparente\n",
    "table(log.lm.step$fitted.values > 0.5, datappq[, \"DepSeuil\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression logistique avec interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec autant de variables et d'interactions donc de paramètres, l'estimation du modèle complet de régression logistique  rencontre des soucis et affiche des *warnings* car certaines probabilité trop bien ajustés (0 ou 1) provoquent des divisions par 0. Ici une procédure *forward* ou  mieux *stepwise* de sélection des variables et interactions  conduit à des résultats raisonnables. Une méthode avec pénalisation L1 peut aussi être utilisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:46.096169Z",
     "start_time": "2019-11-18T09:22:05.997Z"
    }
   },
   "outputs": [],
   "source": [
    "# régression avec le modèle minimum\n",
    "log.qm <- glm(DepSeuil ~ 1, data = datappq,family = binomial)\n",
    "# algorithme stepwise en précisant le plus grand \n",
    "# modèle possible\n",
    "log.qm.step1 <- step(log.qm, direction = \"both\",\n",
    "    scope = list(lower = ~1, upper = ~(JOUR + MOCAGE + TEMPE + \n",
    "            STATION + VentMOD + VentANG + LNO2 + LNO + SRMH2O)^2), \n",
    "    family=binomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:46.158081Z",
     "start_time": "2019-11-18T09:22:06.003Z"
    }
   },
   "outputs": [],
   "source": [
    "anova(log.qm.step1, test = \"Chisq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prévision de l'échantillon test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:46.179001Z",
     "start_time": "2019-11-18T09:22:06.010Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prévision du modèle quadratique\n",
    "pred.log <- predict(log.qm.step1, newdata = datestq, type = \"response\")\n",
    "# Matrice de confusion pour la prévision du \n",
    "# dépassement de seuil\n",
    "table(pred.log > 0.5, datestq[, \"DepSeuil\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparer avec l'approche précédente. Mémoriser les résultats obtenus pour comparer avec les autres méthodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Courbe ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est également possible de construire une courbe ROC en association de la prévision obtenue à partir d'un modèle gaussien. En effet, la variation du seuil théorique de dépassement (150) va faire varier les proportions respectives des taux de vrais et faux positifs. Cela revient encore à faire varier le seuil d'une \"proba\" pour les valeurs de prévisions divisées par 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 6, repr.plot.height = 6)\n",
    "par(mfrow = c(1, 1))\n",
    "rocmocage <- datestr[,  \"MOCAGE\"] / 300 \n",
    "DepSeuil=c(datestr[, \"O3obs\"] > 150)\n",
    "predmocage <- prediction(rocmocage,DepSeuil)\n",
    "perfmocage <- performance(predmocage, \"tpr\", \"fpr\")\n",
    "\n",
    "\n",
    "rocglm <- pred.glm / 300    \n",
    "predglm <- prediction(rocglm,DepSeuil)\n",
    "perfglm <- performance(predglm, \"tpr\", \"fpr\")\n",
    "\n",
    "roclogit <- predict(log.qm.step1, newdata = datestq, type=\"response\")\n",
    "predlogit <- prediction(roclogit, datestq[, \"DepSeuil\"])\n",
    "perflogit <- performance(predlogit, \"tpr\", \"fpr\")\n",
    "\n",
    "plot(perfglm, col = \"blue\",lty=2, main = \"Courbe ROC \\n Mod. quad. backward AIC \")\n",
    "plot(perfmocage,col=\"orange\",lty=2,add=TRUE)\n",
    "plot(perflogit,col=\"green\",lty=1,add=TRUE) \n",
    "\n",
    "legend(\"right\", legend=c(\"Mod. Quad. backward AIC\", \"Mocage\", \"Logit\"),\n",
    "       col=c(\"blue\",\"orange\",\"green\"), lty=c(2,2,1), text.font=1,    cex=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Que sont sensibilité et spécificité d'une courbe ROC?\n",
    "\n",
    "Les résultats obtenus dépendent évidemment en plus de l'échantillonnage initial entre apprentissage et test. Dans le cas où les courbes se croisent, cela signifie qu'il n'y a pas de prévision uniformément meilleure de l'occurrence de dépassement. Cela dépend de la sensibilité ou de la spécificité retenue pour le modèle. Ceci souligne l'importance de la bonne définition du critère à utiliser pour le choix d'une \"meilleure\" méthode. Ce choix dépend directement de celui , \"politique\" ou \"économique\" de sensibilité et / ou spécificité du modèle retenu. En d'autres termes, quel taux de fausse alerte, avec des imputations économiques évidentes, est supportable au regard des dépassements non détectés et donc de la dégradation sanitaire de la population à risque ?\n",
    " \n",
    "C'est une fois ce choix arrêté que le statisticien peut opérer une comparaison des méthodes en présence.\n",
    "\n",
    "**Question** Les performances des deux approches gaussiennes et binomiales sont-elles très différentes ?\n",
    "\n",
    "**Question** Sur le graphe ci-dessus, ajouter la courbe ROC pour le modèle déterministe MOCAGE. Qu'observez-vous?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <FONT COLOR=\"Red\">Épisode 2 : Analyse discriminante, kNN, SVM   </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Analyse discriminante](http://wikistat.fr/pdf/st-m-app-add.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " L'objectif est de comparer les trois méthodes d'analyses discriminantes disponibles dans R: `lda` paramétrique linéaire (homoscédasticité), `qda` paramétrique quadratique (hétéroscédasticité) sous hypothèse gaussienne et celle non-paramétrique des $K$ plus proches voisins.\n",
    " \n",
    "**Question** Quel critère d'affectation est utilisé en LDA ?\n",
    "\n",
    "**Question** Que signifient les hypothèses d'homoscédasticité ou d'hétéroscédasticité ?\n",
    "\n",
    "**Question** Quelle fonction est estimée \"non paramétriquement\" par l'algorithme des $K$ plus proches voisins ?\n",
    " \n",
    "*Attention* : ces techniques n'acceptent par principe que des variables explicatives ou prédictives quantitatives. Néanmoins, une variable qualitative à deux modalités, par exemple le type de jour, peut être considérée comme quantitative sous la forme d'une fonction indicatrice prenant ses valeurs dans $\\{0, 1\\}$. Dans ce dernier cas, il ne faut pas tenter d'interpréter les fonctions de discrimination, juste considérer des erreurs de prévision. La variable *Station* n'est pas prise en compte.\n",
    "\n",
    "La bibliothèque standard de R `MASS` pour l'analyse discriminante ne propose pas de procédure automatique de choix de variable mais, dans cet exemple, les variables sont peu nombreuses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:46.294675Z",
     "start_time": "2019-11-18T09:22:07.823Z"
    }
   },
   "outputs": [],
   "source": [
    "library(MASS) # chargement des librairies\n",
    "library(class) # pour kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:46.341174Z",
     "start_time": "2019-11-18T09:22:07.829Z"
    }
   },
   "outputs": [],
   "source": [
    "# analyse discriminante linéaire\n",
    "disc.lda=lda(DepSeuil~.,data=datappq[,-4]) \n",
    "# analyse discriminante quadratique \n",
    "disc.qda=qda(DepSeuil~.,data=datappq[,-4]) \n",
    "# k plus proches voisins\n",
    "disc.knn=knn(datappq[,c(-4,-10)],datappq[,c(-4,-10)],datappq$DepSeuil,k=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noter le manque d'homogénéité des commandes de R issues de librairies différentes. L'indice de colonne négatif ($-10$) permet de retirer la colonne contenant la variable à prédire de type facteur. Celle-ci est mentionnée en troisième paramètre pour les données d'apprentissage. La librairie [caret](http://topepo.github.io/caret/index.html) contourne ces difficultés en englobant toutes les librairies d'apprentissage et en homogénéisant les appels pour l'estimation et la prévision des modèles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "lda.fit<-train(DepSeuil~.,data=datappq[,-4],method=\"lda\")\n",
    "qda.fit<-train(DepSeuil~.,data=datappq[,-4],method=\"qda\")\n",
    "knn.fit<-train(DepSeuil~.,data=datappq[,-4],method=\"knn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation de l'erreur de prévision par validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sans utiliser la librairie `caret`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:46.362843Z",
     "start_time": "2019-11-18T09:22:08.228Z"
    }
   },
   "outputs": [],
   "source": [
    "# erreur par validation croisée  en analyse discriminante linéaire\n",
    "disc.lda=lda(DepSeuil~.,data=datappq[,-4],CV=T) \n",
    "# estimer le taux d'erreur à partir de la matrice de confusion\n",
    "table(datappq[,\"DepSeuil\"],disc.lda$class)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:46.385631Z",
     "start_time": "2019-11-18T09:22:08.238Z"
    }
   },
   "outputs": [],
   "source": [
    "# analyse discriminante quadratique\n",
    "disc.qda=qda(DepSeuil~.,data=datappq[,-4],CV=T)  \n",
    "table(datappq[,\"DepSeuil\"],disc.qda$class) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour Knn, le choix du nombre de voisins $K$ doit être optimisé par validation croisée mais la procédure proposée par la bibliothèque `class` est celle *leave-one-out*, donc trop coûteuse en calcul pour des gros fichiers. Il serait simple de la programmer mais la librairie `e1071` propose déjà plusieurs fonctions de validation croisée pour de nombreuses techniques de discrimination. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:46.922719Z",
     "start_time": "2019-11-18T09:22:08.551Z"
    }
   },
   "outputs": [],
   "source": [
    "# k plus proches voisins: optimisation de k\n",
    "library(e1071)\n",
    "plot(tune.knn(as.matrix(datappq[,c(-4,-10)]),as.factor(datappq[,10]),k=2:20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Quelle procédure de validation croisée est exécutée par défaut par la fonction `tune()` ?\n",
    "\n",
    "**Question** Lancez plusieurs exécutions successives de cette \"optimisation\". Pourquoi la valeur de $K$ optimale diffère à chaque exécution ? Comment choisir $K$ ?\n",
    "\n",
    "**Question** Comparez avec les erreurs précédentes estimées également par validation croisée. Quelle analyse discriminante retenir ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec la librairie `caret`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation croisée avec 10 folds\n",
    "param_train<-trainControl(method=\"cv\",number=10)\n",
    "# erreur par validation croisée  en analyse discriminante linéaire\n",
    "lda.fit <- train(DepSeuil~.,data=datappq[,-4],method=\"lda\",trControl=param_train)\n",
    "# estimer le taux d'erreur à partir de la matrice de confusion\n",
    "table(datappq[,\"DepSeuil\"],predict(lda.fit,datappq[,-c(4,10)])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erreur par validation croisée  en analyse discriminante quadratique\n",
    "qda.fit <- train(DepSeuil~.,data=datappq[,-4],method=\"qda\",trControl=param_train)\n",
    "# estimer le taux d'erreur à partir de la matrice de confusion\n",
    "table(datappq[,\"DepSeuil\"],predict(qda.fit,datappq[,-c(4,10)])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erreur par validation croisée  en kNN\n",
    "knn.fit <- train(DepSeuil~.,data=datappq[,-4],method=\"knn\",trControl=param_train,tuneLength=20)\n",
    "# estimer le taux d'erreur à partir de la matrice de confusion\n",
    "table(datappq[,\"DepSeuil\"],predict(knn.fit,datappq[,-c(4,10)])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prévision de l'échantillon test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrices de confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les commandes suivantes calculent la matrice de confusion sur le jeu de données test pour chaque méthode d'analyse discriminante optimisée par validation croisée. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## méthode LDA\n",
    "table(predict(lda.fit,datestq[,-4]),datestq[,\"DepSeuil\"])\n",
    "sum(predict(lda.fit,datestq[,-4])!=datestq[,\"DepSeuil\"])/nrow(datestq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## méthode QDA\n",
    "table(predict(qda.fit,datestq[,-4]),datestq[,\"DepSeuil\"])\n",
    "sum(predict(qda.fit,datestq[,-4])!=datestq[,\"DepSeuil\"])/nrow(datestq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## méthode KNN\n",
    "table(predict(knn.fit,datestq[,-4]),datestq[,\"DepSeuil\"])\n",
    "sum(predict(knn.fit,datestq[,-4])!=datestq[,\"DepSeuil\"])/nrow(datestq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi utiliser la fonction `confusionMatrix()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix(predict(knn.fit,datestq[,-4]),datestq[,\"DepSeuil\"],positive=\"TRUE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Courbes ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va ici comparer via la courbe ROC les méthodes d’analyse discriminante LDA, QDA, KNN ainsi que la régression logistique (voir Episode 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code de l'épisode 1 pour la régression logistique\n",
    "log.qm <- glm(DepSeuil ~ 1, data = datappq,family = binomial)\n",
    "log.qm.step1 <- step(log.qm, direction = \"both\",\n",
    "    scope = list(lower = ~1, upper = ~(JOUR + MOCAGE + TEMPE + \n",
    "            STATION + VentMOD + VentANG + LNO2 + LNO + SRMH2O)^2), \n",
    "    family=binomial,trace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(pROC)\n",
    "rocobjlda<-roc(datestq$DepSeuil,predict(lda.fit,datestq[,-4],type=\"prob\")[,2])\n",
    "rocobjqda<-roc(datestq$DepSeuil,predict(qda.fit,datestq[,-4],type=\"prob\")[,2])\n",
    "rocobjknn<-roc(datestq$DepSeuil,predict(knn.fit,datestq[,-4],type=\"prob\")[,2])\n",
    "rocobjlogit<-roc(datestq[, \"DepSeuil\"],predict(log.qm.step1, newdata = datestq, type=\"response\"))\n",
    "\n",
    "options(repr.plot.width = 10, repr.plot.height = 8)\n",
    "ggroc(list(lda=rocobjlda,qda=rocobjqda,knn=rocobjknn,logit=rocobjlogit),legacy.axes=T)+\n",
    "  xlab(\"False Positive Rate\")+\n",
    "  ylab(\"True Positive Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Une méthode est-elle uniformément meilleure sur cet échantillon test ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Séparateur à Vaste Marge (SVM)](http://wikistat.fr/pdf/st-m-app-svm.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Malgré les assurances théoriques concernant ce type d'algorithme, les résultats dépendent fortement du choix des paramètres. Nous nous limiterons d'abord au noyau Gaussien (choix par défaut) ; la fonction `tune.svm` permet de tester facilement plusieurs situations en estimant la qualité de prévision par validation croisée sur une grille. Le temps d'exécution en R est un peu long... \n",
    "\n",
    "**Question** Le temps d'exécution pour les SVM est-il plus sensible au nombre d'observations ou au nombre de variables ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression\n",
    "\n",
    "Bien qu'initialement développés dans le cas d'une variable binaire, les SVM ont été étendus aux problèmes de régression. L'estimation et l'optimisation du coefficient de pénalisation sont obtenues par les commandes suivantes.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(e1071)\n",
    "help(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.reg0 = svm(O3obs ~ ., data = datappr)\n",
    "summary(svm.reg0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set.seed(2021)\n",
    "svm.reg.tune = tune.svm(O3obs ~ ., data = datappr, cost = c(1, 1.5, 2, 2.5, 3, 3.5), \n",
    "    gamma = seq(0.02, 0.1, by = 0.02))\n",
    "plot(svm.reg.tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par défaut la pénalisation (cost) vaut 1.\n",
    "\n",
    "**Question** Notez la pénalisation optimale pour le noyau considéré (Gaussien). Ré-estimez le modèle supposé optimal avant de tracer le graphe des résidus. Comme précédemment, observez que plusieurs exécutions conduisent à des résultats différents et donc que l'optimisation de ce paramètre est pour le moins délicate.\n",
    "\n",
    "**Question** Quels autres noyaux sont disponibles dans cette implémentation des SVM ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.reg = svm(O3obs ~ ., data = datappr, cost = svm.reg.tune$best.parameters$cost, \n",
    "    gamma = svm.reg.tune$best.parameters$gamma)\n",
    "summary(svm.reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul et graphe des résidus\n",
    "fit.svmr=fit.svmr=svm.reg$fitted\n",
    "res.svmr=fit.svmr-datappr[,\"O3obs\"]\n",
    "gplot.res(fit.svmr,res.svmr,titre=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observez l'effet ''couloir'' sur les résidus. \n",
    "\n",
    "**Question** Qu'est-ce qui cause le rapprochement des résidus dans un \"couloir\"? Qu'observez-vous lorsque vous faites varier les paramètres cost et epsilon?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimisation\n",
    "svm.dis.tune = tune.svm(DepSeuil ~ ., data = datappq, cost = c(1,1.25,1.5,1.75,2), \n",
    "    gamma = seq(0.02, 0.1, by = 0.02))\n",
    "plot(svm.dis.tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apprentissage\n",
    "svm.dis.tune$best.parameters\n",
    "svm.dis=svm(DepSeuil~.,data=datappq,cost = svm.reg.tune$best.parameters$cost, \n",
    "    gamma = svm.reg.tune$best.parameters$gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prévision de l'échantillon test\n",
    "\n",
    "#### Erreur de régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.svmr=predict(svm.reg,newdata=datestr)\n",
    "# Erreur quadratique moyenne de prévision\n",
    "sum((pred.svmr-datestr[,\"O3obs\"])^2)/nrow(datestr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erreur de classification (matrices de confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion pour la prévision du dépassement de seuil (régression)\n",
    "table(pred.svmr>150,datestr[,\"O3obs\"]>150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Même chose pour la discrimination\n",
    "pred.svmq=predict(svm.dis,newdata=datestq)\n",
    "table(pred.svmq,datestq[,\"DepSeuil\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Courbes ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rocsvmr = pred.svmr/300\n",
    "predsvmr = prediction(rocsvmr, datestq$DepSeuil)\n",
    "perfsvmr = performance(predsvmr, \"tpr\", \"fpr\")\n",
    "# re-estimer le modèle pour obtenir des probabilités de classe plutôt que des\n",
    "# classes\n",
    "svm.dis = svm(DepSeuil ~ ., data = datappq, cost = 1.25, probability = TRUE)\n",
    "pred.svmq = predict(svm.dis, newdata = datestq, probability = TRUE)\n",
    "rocsvmq = attributes(pred.svmq)$probabilities[, 2]\n",
    "predsvmq = prediction(rocsvmq, datestq$DepSeuil)\n",
    "perfsvmq = performance(predsvmq, \"tpr\", \"fpr\")\n",
    "# tracer les courbes ROC en les superposant pour mieux comparer\n",
    "plot(perflogit, col = \"blue\")\n",
    "plot(perfsvmr, col = \"red\", lty = 2, add = TRUE)\n",
    "plot(perfsvmq, col = \"green\", add = TRUE)\n",
    "\n",
    "\n",
    "legend(\"right\", legend=c(\"Logit\",\"SVR\", \"SVM\"),\n",
    "       col=c(\"blue\",\"red\",\"green\"), lty=c(1,2,1), text.font=1,    cex=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question** Les SVM apportent-ils une amélioration?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <FONT COLOR=\"Red\">Épisode 3 :  CART, Agrégation de modèles  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Arbre de décision binaire (CART)](http://wikistat.fr/pdf/st-m-app-cart.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librairie `rpart` est celle la plus couramment utilisée pour la construction d'arbres de décision. Deux types d'arbres peuvent être estimés selon que la variable à modéliser est la concentration d'ozone (arbre de régression) ou directement le dépassement du seuil (arbre de discrimination ou de décision). Différents paramètres contrôlent l'exécution de l'algorithme : la pénalisation minimale (cp) pour la construction de l'arbre maximal, le nombre minimal d'observations par noeud, le nombre de validations croisées (par défaut 10)... cf. l'aide en ligne (`?rpart.control`) pour plus de détails mais celle-ci n'est pas très explicite sur certains paramètres.\n",
    "\n",
    "NB. Une séquence de valeurs de la pénalisation `cp` est associée à une séquence d'arbres emboîtés.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation et élagage de l'arbre de régression\n",
    "**Question** Quel critère est optimisé lors de la création d'un noeud de l'arbre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:47.088662Z",
     "start_time": "2019-11-18T09:22:10.466Z"
    }
   },
   "outputs": [],
   "source": [
    "library(rpart) \n",
    "help(rpart)\n",
    "help(rpart.control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.reg=rpart(O3obs~.,data=datappr,control=rpart.control(cp=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La commande `summary(tree.reg)` fournit un descriptif de l'arbre obtenu mais un graphe est  préférable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:47.181644Z",
     "start_time": "2019-11-18T09:22:10.473Z"
    }
   },
   "outputs": [],
   "source": [
    "library(rpart.plot)\n",
    "options(repr.plot.width = 15, repr.plot.height = 10)\n",
    "rpart.plot(tree.reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'arbre est illisible et présente trop de feuilles pour une bonne prévision (sur-apprentissage), il est nécessaire d'en réduire le nombre par élagage. Les commandes suivantes calculent les prévisions obtenues par validation croisée 10-fold pour chaque arbre élagué suivant les valeurs successives du coefficient de complexité. La séquence de ces valeurs est implicitement celle fournit par `rpart`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:47.218915Z",
     "start_time": "2019-11-18T09:22:10.686Z"
    }
   },
   "outputs": [],
   "source": [
    "help(xpred.rpart)\n",
    "xmat<-xpred.rpart(tree.reg,xval=10) \n",
    "# one row for each observation and one column for each complexity value\n",
    "\n",
    "# Cross-validation error par valeur de CP\n",
    "CVerr<-apply((xmat-datappr[,\"O3obs\"])^2,2,sum)\n",
    "\n",
    "plotcp(tree.reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cherchez la valeur de `cp` correspondant à la plus petite erreur puis utilisez la pour la construction del'arbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:47.236505Z",
     "start_time": "2019-11-18T09:22:10.912Z"
    }
   },
   "outputs": [],
   "source": [
    "as.numeric(attributes(which.min(CVerr))$names)\n",
    "tree.reg=rpart(O3obs~.,data=datappr,control=rpart.control(cp=as.numeric(attributes(which.min(CVerr))$names)))\n",
    "rpart.plot(tree.reg,type=5,extra=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librairie `partykit` propose une construction graphique de l'arbre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:47.731129Z",
     "start_time": "2019-11-18T09:22:11.150Z"
    }
   },
   "outputs": [],
   "source": [
    "library(partykit)\n",
    "plot(as.party(tree.reg), type=\"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fenêtre est trop petite pour représenter les distributions (histogramme) de la variable cible (concentration en ozone) dans chaque feuille. \n",
    "\n",
    "**Question** Quelle est la variable qui contribue le plus à l'interprétation ?\n",
    "\n",
    "Graphe des résidus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:47.831850Z",
     "start_time": "2019-11-18T09:22:11.369Z"
    }
   },
   "outputs": [],
   "source": [
    "fit.tree=predict(tree.reg)\n",
    "res.tree=fit.tree-datappr[,\"O3obs\"]\n",
    "gplot.res(fit.tree,res.tree,\"residus de tree.reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** A quoi est due la structure particulière de ce graphe ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici un exemple de code pour faire cet élagage avec la librairie `caret`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl <- trainControl(method = \"cv\",number = 10)\n",
    "treecaret <- train(O3obs~.,data=datappr,method = \"rpart\",trControl = ctrl,tuneLength =20)\n",
    "print(paste(\"Valeur de cp retenue = \",treecaret$bestTune,sep=\"\"))\n",
    "rpart.plot(treecaret$finalModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation et élagage d'un arbre de discrimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cas d'une discrimination, le critère par défaut est l'indice de concentration de Gini ; il est possible de préciser un autre critère (split=\"information\") ainsi que des poids sur les observations, une matrice de coûts de mauvais classement ainsi que des probabilités a priori (`?rpart` pour plus de détails).\n",
    "\n",
    "**Question** Quel autre critère d'hétérogénéité est utilisé ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:47.936071Z",
     "start_time": "2019-11-18T09:22:12.009Z"
    }
   },
   "outputs": [],
   "source": [
    "tree.dis=rpart(DepSeuil~.,data=datappq,parms=list(split=\"information\"),cp=0.001)\n",
    "rpart.plot(tree.dis) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La même procédure d'élagage par validation croisée est mise en place mais avec une expression différente de l'erreur de prévision: taux de mal classés plutôt qu'erreur quadratique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:47.989031Z",
     "start_time": "2019-11-18T09:22:12.228Z"
    }
   },
   "outputs": [],
   "source": [
    "xmat = xpred.rpart(tree.dis)\n",
    "# Comparaison des valeurs prédite et observée\n",
    "xerr=datappq$DepSeuil!= (xmat>1.5) \n",
    "# Calcul  des estimations des taux d'erreur\n",
    "CVerr=apply(xerr, 2, sum)/nrow(xerr)\n",
    "CVerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:48.218396Z",
     "start_time": "2019-11-18T09:22:12.241Z"
    }
   },
   "outputs": [],
   "source": [
    "tree.dis=rpart(DepSeuil~.,data=datappq,parms=list(split=\"information\"),cp=as.numeric(attributes(which.min(CVerr))$names))\n",
    "rpart.plot(tree.dis,type=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec la librairie `caret`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl <- trainControl(method = \"cv\",number = 10)\n",
    "treecaret <- train(DepSeuil~.,data=datappq,method = \"rpart\",trControl = ctrl,tuneLength =20,metric=\"Accuracy\")\n",
    "print(paste(\"Valeur de cp retenue = \",treecaret$bestTune,sep=\"\"))\n",
    "rpart.plot(treecaret$finalModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prévision de l'échantillon test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Différentes prévisions sont considérées assorties des erreurs estimées sur l'échantillon test. Prévision quantitative de la concentration, prévision de dépassement à partir de la prévision quantitative et directement la prévision de dépassement à partir de l'arbre de décision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erreur de régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:48.248763Z",
     "start_time": "2019-11-18T09:22:12.672Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calcul des prévisions\n",
    "pred.treer=predict(tree.reg,newdata=datestr)\n",
    "# Erreur quadratique moyenne de prévision en régression\n",
    "sum((pred.treer-datestr[,\"O3obs\"])^2)/nrow(datestr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erreur de classification (matrice de confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:48.267073Z",
     "start_time": "2019-11-18T09:22:12.681Z"
    }
   },
   "outputs": [],
   "source": [
    "# Matrice de confusion pour la prévision du \n",
    "# dépassement de seuil (régression)\n",
    "  #table(pred.treer>150,datestr[,\"O3obs\"]>150)\n",
    "confusionMatrix(as.factor(pred.treer>150),as.factor(datestr[,\"O3obs\"]>150))$table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:48.285260Z",
     "start_time": "2019-11-18T09:22:12.688Z"
    }
   },
   "outputs": [],
   "source": [
    "# Même chose pour l'arbre de discrimination\n",
    "pred.treeq=predict(tree.dis,newdata=datestq,type=\"class\")\n",
    "  #table(pred.treeq,datestq[,\"DepSeuil\"])\n",
    "confusionMatrix(pred.treeq,datestq[,\"DepSeuil\"])$table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Quelle stratégie semble meilleure à ce niveau ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Courbes ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROCregtree=pred.treer/300\n",
    "predregtree=prediction(ROCregtree,datestq$DepSeuil)\n",
    "perfregtree=performance(predregtree,\"tpr\",\"fpr\")\n",
    "ROCdistree=predict(tree.dis,newdata=datestq,type=\"prob\")[,2]\n",
    "preddistree=prediction(ROCdistree,datestq$DepSeuil)\n",
    "perfdistree=performance(preddistree,\"tpr\",\"fpr\")\n",
    "# tracer les courbes ROC en les superposant \n",
    "# pour mieux comparer\n",
    "\n",
    "options(repr.plot.width = 8, repr.plot.height = 6)\n",
    "plot(perflogit,col=\"blue\")\n",
    "plot(perfregtree,col=\"orange\",lty=2,add=TRUE) \n",
    "plot(perfdistree,col=\"green\",add=TRUE)  \n",
    "\n",
    "legend(\"right\", legend=c(\"Logit\", \"TreeReg\", \"TreeDis\"),\n",
    "       col=c(\"blue\",\"orange\",\"green\"), lty=c(1,2,1), text.font=1,    cex=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Comparez les qualités de prévision. Une meilleure méthode se dégage-t-elle ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Agrégation de modèles](http://wikistat.fr/pdf/st-m-app-agreg.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Les sections précédentes ont permis d'expérimenter les constructions d'un modèle de prévision assorties du problème récurrent lié à l'optimisation de la complexité d'un modèle. Cette section aborde d'autres stratégies dont l'objectif est de s'affranchir de ce problème de choix par des méthodes se montrant très peu sensibles au sur-apprentissage ; c'est le cas des algorithmes d'agrégation de modèles.\n",
    "\n",
    "Cette section propose de mettre en évidence la plus ou moins grande influence des paramètres de ces méthodes.\n",
    "\n",
    "* *Random forest* : nombre d'arbres et `mtry` et intérêt des critères de Breiman permettant de mesurer l'influence des variables au sein d'une famille agrégée de modèles. \n",
    "\n",
    "* *Boosting* : profondeur d'arbre, nombre d'itérations ou d'arbres et coefficient de *shrinkage*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forêts aléatoires\n",
    "Le programme est disponible dans la librairie `randomForest`. Il est écrit en fortran, donc en principe efficace en terme de rapidité d'exécution, et facile à utiliser grâce à une interface avec R. La comparaison avec Python montre qu'il n'est finalement pas très efficace sans doute à cause de l'interface avec R. Les paramètres et sorties sont explicités dans l'aide en ligne.\n",
    "\n",
    "En R et pour des gros fichiers, privilégier la librairie `ranger` à la place de `randomForest`.\n",
    "\n",
    "**Question** Quel est le paramètre `mtry` de la fonction `randomForest`?\n",
    "\n",
    "**Question** En quoi le bagging est un cas particulier des forêts aléatoires ?\n",
    "Le bagging ne sera pas traité dans ce TP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(randomForest)\n",
    "help(randomForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf.reg=randomForest(O3obs~., data=datappr,xtest=datestr[,-2],ytest=datestr[,\"O3obs\"],\n",
    "   ntree=500,do.trace=50,importance=TRUE)\n",
    "attributes(rf.reg)\n",
    "rf.reg$mtry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Quelles est la valeur par défaut de `mtry` ?\n",
    "\n",
    "Relancez en faisant varier les paramètres `mtry` et `ntree` pour expérimenter leur peu d'influence sur les erreurs.\n",
    "\n",
    "Calcul et graphe des résidus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.rfr=rf.reg$predicted\n",
    "res.rfr=fit.rfr-datappr[,\"O3obs\"]\n",
    "gplot.res(fit.rfr,res.rfr,titre=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrimination\n",
    "**Question** Quelle est la valeur par défaut de `mtry`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.dis=randomForest(DepSeuil~.,data=datappq,xtest=datestq[,-10],ytest=datestq[,\n",
    "   \"DepSeuil\"],ntree=500,do.trace=50,importance=TRUE)\n",
    "rf.dis$importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.dis$mtry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Commentez les erreurs, testez d'autres exécutions avec d'autres valeurs des paramètres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance des variables\n",
    "Le modèle obtenu est ininterprétable mais des coefficients estiment les contributions des variables dans leur participation à la discrimination. Comparer avec les variables sélectionnées par les autres modèles dans l'épisode 1. Deux critères d'importance sont proposés.\n",
    "\n",
    "**Question** Quelles sont les deux mesures d'importance des variables ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort(round(importance(rf.reg), 2)[,1], decreasing=TRUE)\n",
    "sort(round(importance(rf.dis), 2)[,4], decreasing=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varImpPlot(rf.reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varImpPlot(rf.dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggRandomForests)\n",
    "plot(gg_vimp(rf.reg))\n",
    "plot(gg_vimp(rf.dis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prévision de l'échantillon test\n",
    "\n",
    "#### En régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forêts aléatoires\n",
    "pred.rfr=rf.reg$test$predicted\n",
    "# Erreur quadratique moyenne de prévision\n",
    "sum((pred.rfr-datestr[,\"O3obs\"])^2)/nrow(datestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forêts aléatoires\n",
    "# Matrice de confusion pour la prévision du \n",
    "# dépassement de seuil (régression)\n",
    "table(pred.rfr>150,datestr[,\"O3obs\"]>150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.rfq=rf.dis$test$predicted\n",
    "table(pred.rfq,datestq[,\"DepSeuil\"])\n",
    "confusionMatrix(pred.rfq,datestq[,\"DepSeuil\"],positive=\"TRUE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Qu'indique la comparaison des courbes ROC ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting\n",
    "\n",
    "Deux librairies proposent des versions relativement  sophistiquées des algorithmes de *boosting* dans R. La librairie *boost* propose 4 approches : *adaboost, bagboost* et deux *logitboost*. Développée pour une problématique particulière: l'analyse des données d'expression génomique, elle n'est peut-être pas complètement adaptée aux données étudiées ; elle se limite à des prédicteurs quantitatifs et peut fournir des résultats étranges. La librairie *gbm* lui est préférée ; elle offre aussi plusieurs versions dépendant de la fonction coût choisie. Une librairie plus récente `xgboost` intègre des fonctionnalités de parallélisation (pas sous Windows) et fait intervenir plusieurs autres paramètres.\n",
    "\n",
    "La variable à prévoir doit être codée numériquement (0-1) pour cette implémentation. Le nombre d'itérations, ou nombre d'arbres, est paramétré ainsi qu'un coefficient de rétrécissement (*shrinkage*).\n",
    "\n",
    "**Question** Comment intervient le *shrinkage* en *boosting*? \n",
    "\n",
    "**Question** Pour quel boosting? Ou que signifie `gbm`?\n",
    "\n",
    "*Attention*, par défaut, ce paramètre a une valeur très faible (0.001) et il faut un nombre important d'itérations (d'arbres) pour atteindre une estimation raisonnable. La qualité est visualisée par un graphe représentant l'évolution de l'erreur d'apprentissage. D'autre part, une procédure de validation croisée est incorporée afin d'optimiser le nombre d'arbres car la version de *boosting* considérée est (légèrement) sujette au sur-apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class(ozone$STATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(gbm)\n",
    "boost.reg = gbm(O3obs ~ ., data = datappr, distribution = \"gaussian\", n.trees = 500, \n",
    "    cv.folds = 10, n.minobsinnode = 5, shrinkage = 0.03, verbose = FALSE)\n",
    "# fixer verbose à FALSE pour éviter trop de sorties\n",
    "plot(boost.reg$cv.error, type = \"l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre optimal d'itérations par valiation croisée\n",
    "best.iter=gbm.perf(boost.reg,method=\"cv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut s'assurer de l'absence d'un phénomène de sur-apprentissage critique en calculant puis traçant l'évolution de l'erreur sur l'échantillon test en fonction du nombre d'arbre dans le modèle. L'erreur reste stable autour du nombre d'arbres sélectionné et matérialisé par la ligne verticale. \n",
    "\n",
    "**Question** Testez ces fonctions en faisant varier le coefficient de rétrécissement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=numeric()\n",
    "for (i in 10:500){\n",
    "pred.test=predict(boost.reg,newdata=datestr,n.trees=i)\n",
    "err=sum((pred.test-datestr[,\"O3obs\"])^2)/nrow(datestr)\n",
    "test=c(test,err)}\n",
    "plot(10:500,test,type=\"l\")\n",
    "abline(v=best.iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrimination\n",
    "Attention, la variable à modéliser doit être codée $(0, 1)$ et il faut préciser un autre paramètre de distribution pour considérer le bon terme d'erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datappq2=datappq\n",
    "datappq2[,\"DepSeuil\"]=as.numeric(datappq[,\"DepSeuil\"])-1\n",
    "boost.dis=gbm(DepSeuil~.,data=datappq2,distribution=\"adaboost\",n.trees=500, cv.folds=10,\n",
    "              n.minobsinnode = 5,shrinkage=0.03,verbose=FALSE)\n",
    "plot(boost.dis$cv.error,type=\"l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre optimal d'itérations \n",
    "best.ited=gbm.perf(boost.dis,method=\"cv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour la régression, il est possible de faire varier le coefficient de rétrécissement en l'associant au nombre d'arbres dans le modèle.\n",
    "\n",
    "Calcul des résidus et graphe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.boostr=boost.reg$fit\n",
    "res.boostr=fit.boostr-datappr[,\"O3obs\"]\n",
    "gplot.res(fit.boostr,res.boostr,titre=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prévision de l'échantillon test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erreur de régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " pred.boostr=predict(boost.reg,newdata=datestr,n.trees=best.iter)\n",
    "# Erreur quadratique moyenne de prévision\n",
    "sum((pred.boostr-datestr[,\"O3obs\"])^2)/nrow(datestr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erreur de classification (matrices de confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion pour la prévision \n",
    "# du dépassement de seuil (régression)\n",
    "table(pred.boostr>150,datestr[,\"O3obs\"]>150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Même chose pour la discrimination\n",
    "pred.boostd=predict(boost.dis,newdata=datestq,n.trees=best.ited)\n",
    "table(as.factor(sign(pred.boostd)),datestq[,\"DepSeuil\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Courbes ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forêts aléatoires\n",
    "rocrfr=pred.rfr/300\n",
    "predrfr=prediction(rocrfr,datestq$DepSeuil)\n",
    "perfrfr=performance(predrfr,\"tpr\",\"fpr\")\n",
    "\n",
    "# Boosting\n",
    "rocbstr=pred.boostr/300\n",
    "predbstr=prediction(rocbstr,datestq$DepSeuil)\n",
    "perfbstr=performance(predbstr,\"tpr\",\"fpr\")\n",
    "\n",
    "# tracer les courbes ROC en les superposant \n",
    "# pour mieux comparer\n",
    "plot(perflogit,col=\"blue\")\n",
    "plot(perfrfr,col=\"purple\",lty=2,add=TRUE)  \n",
    "plot(perfbstr,col=\"green\",add=TRUE) \n",
    "\n",
    "legend(\"right\", legend=c(\"Logit\",\"RF\", \"Boosting\"),\n",
    "       col=c(\"blue\",\"purple\",\"green\"), lty=c(1,2,1), text.font=1,    cex=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Quelle  stratégie d'agrégation de modèles vous semble fournir le meilleur résultat de prévision? \n",
    "\n",
    "**Question** Est-elle, sur ce jeu de données, plus efficace que les modèles classiques expérimentés auparavant ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <FONT COLOR=\"Red\">Épisode 4 : Réseaux de neurones </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Réseau de neurones](http://wikistat.fr/pdf/st-m-app-rn.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il s'agit d'estimer un modèle de type *perceptron* avec en entrée les variables qualitatives ou quantitatives et en sortie la variable à prévoir. Des fonctions R pour l'apprentissage d'un perceptron élémentaire ont été réalisées par différents auteurs et sont accessibles sur le réseau. La librairie `nnet` de (Ripley, 1999), est limitée au perceptron à une couche. Ce n'est pas de l'*apprentissage profond* ! mais suffisant dans bien des cas. Une librairie R associée au logiciel éponyme H2O propose des réseaux à plusieurs couches et \"convolutionnels\".\n",
    "\n",
    "Comme pour les arbres, la variable à expliquer est soit quantitative soit qualitative ; la fonction de transfert du neurone de sortie d'un réseau doit être adaptée en conséquence. \n",
    "\n",
    "**Question** Quelle fonction de transfert est utilisée pour le dernier neurone en régression ? en classification  binaire? en classification multiclasse ? \n",
    "\n",
    "**Question** Quel est le choix par défaut pour les neurones de la couche cachée?\n",
    "\n",
    "Différentes stratégies sont proposées pour éviter le sur-apprentissage. La première consiste à optimiser le nombre de neurones sur la couche cachée. Très approximativement il est d'usage de considérer, qu'en moyenne, il faut une taille d'échantillon d'apprentissage 10 fois supérieure au nombre de poids c'est-à-dire au nombre de paramètres à estimer. On remarque qu'ici la taille de l'échantillon d'apprentissage (832) est modeste pour une application raisonnable du perceptron. Seuls des nombres restreints de neurones peuvent être considérés et sur une seule couche cachée. \n",
    "\n",
    "**Question** Quel est le paramètre `decay` de la fonction `nnet`?\n",
    "\n",
    "**Question** Indiquez une autre façon d'éviter le sur-apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cas de la régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:48.781644Z",
     "start_time": "2019-11-18T09:22:14.471Z"
    }
   },
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "library(nnet)\n",
    "# apprentissage\n",
    "# attention au paramètre linout dans le cas de la régression\n",
    "nnet.reg=nnet(O3obs~.,data=datappr,size=5,decay=1,linout=TRUE,maxit=500) \n",
    "summary(nnet.reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La commande donne la \"trace\" de l'exécution avec le comportement de la convergence mais le détail des poids de chaque entrée de chaque neurone ne constitue pas un résultats très explicite ! \n",
    "\n",
    "**Question** Contrôlez le nombre de poids estimés.\n",
    "\n",
    "L'optimisation des paramètres nécessite encore le passage par la validation croisée. Il n'y a pas de fonction dans la librairie `nnet` permettant de le faire mais la fonction ` tune.nnet` de la librairie `e1071` est adaptée à cette démarche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:00.187792Z",
     "start_time": "2019-11-18T09:22:14.679Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(e1071)\n",
    "plot(tune.nnet(O3obs~.,data=datappr,size=c(2,3,4),decay=c(1,2,3),maxit=200,linout=TRUE))\n",
    "plot(tune.nnet(O3obs~.,data=datappr,size=4:5,decay=1:10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire éventuellement varier la grille des paramètres (zoom), notez la taille et le `decay` optimaux. Il faudrait aussi  faire varier le nombre total d'itérations. Cela risque de prendre un peu de temps ! Notez également que chaque exécution donne des résultats différents... il n'est donc pas très utile d'y passer beaucoup de temps !\n",
    "\n",
    "**Question** Ré-estimez le modèle supposé optimal avant de tracer le graphe des résidus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:00.436424Z",
     "start_time": "2019-11-18T09:22:14.895Z"
    }
   },
   "outputs": [],
   "source": [
    "nnet.reg=nnet(O3obs~.,data=datappr,size=3,decay=2,linout=TRUE,maxit=200)\n",
    "# calcul et graphe des résidus\n",
    "fit.nnetr=predict(nnet.reg,data=datappr)\n",
    "res.nnetr=fit.nnetr-datappr[,\"O3obs\"]\n",
    "gplot.res(fit.nnetr,res.nnetr,titre=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cas de la discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:00.463554Z",
     "start_time": "2019-11-18T09:22:15.102Z"
    }
   },
   "outputs": [],
   "source": [
    "# apprentissage\n",
    "nnet.dis=nnet(DepSeuil~.,data=datappq,size=5,decay=0) \n",
    "summary(nnet.reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La validation croisée est toujours nécessaire afin de tenter d'optimiser les choix en présence : nombre de neurones, `decay` et éventuellement le nombre maximal d'itérations. \n",
    "\n",
    "L'initialisation de l'apprentissage d'un réseau de neurone comme celle de l'estimation de l'erreur par validation croisée sont aléatoires. Chaque exécution donne donc des résultats différents. À ce niveau, il serait intéressant de construire un plan d'expérience à deux facteurs (ici, les paramètres de taille et `decay`) de chacun trois niveaux. Plusieurs réalisations pour chaque combinaison des niveaux suivies d'un test classique d'anova permettraient de se faire une idée plus juste de l'influence de ces facteurs sur l'erreur. \n",
    "\n",
    "**Question** Notez la taille et le `decay` optimaux et ré-estimez le modèle pour ces valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:25.823681Z",
     "start_time": "2019-11-18T09:22:15.309Z"
    }
   },
   "outputs": [],
   "source": [
    "plot(tune.nnet(DepSeuil~.,data=datappq,size=c(3,4,5),decay=c(0,1,2),maxit=200,linout=FALSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:25.936811Z",
     "start_time": "2019-11-18T09:22:15.315Z"
    }
   },
   "outputs": [],
   "source": [
    "nnet.dis=nnet(DepSeuil~.,data=datappq,size=5,decay=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prévisions de l'échantillon test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Différentes prévisions sont considérées assorties des erreurs estimées sur l'échantillon test. Prévision quantitative de la concentration, prévision de dépassement à partir de la prévision quantitative et directement la prévision de dépassement à partir de l'arbre de décision. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erreur de régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:25.972074Z",
     "start_time": "2019-11-18T09:22:15.713Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calcul des prévisions\n",
    "pred.nnetr=predict(nnet.reg,newdata=datestr)\n",
    "pred.nnetq=predict(nnet.dis,newdata=datestq) \n",
    "# Erreur quadratique moyenne de prévision\n",
    "sum((pred.nnetr-datestr[,\"O3obs\"])^2)/nrow(datestr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erreur de classification (matrice de confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:25.996337Z",
     "start_time": "2019-11-18T09:22:15.718Z"
    }
   },
   "outputs": [],
   "source": [
    "# Matrice de confusion pour la prévision du \n",
    "# dépassement de seuil (régression)\n",
    "table(pred.nnetr>150,datestr[,\"O3obs\"]>150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "confusionMatrix(as.factor(pred.nnetr>150),as.factor(datestr[,\"O3obs\"]>150))$table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:26.022088Z",
     "start_time": "2019-11-18T09:22:15.725Z"
    }
   },
   "outputs": [],
   "source": [
    "# Même chose pour la discrimination\n",
    "table(pred.nnetq>0.5,datestq[,\"DepSeuil\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Courbes ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:26.112355Z",
     "start_time": "2019-11-18T09:22:15.926Z"
    }
   },
   "outputs": [],
   "source": [
    "library(ROCR)\n",
    "\n",
    "\n",
    "roclogit <- predict(log.qm.step1, newdata = datestq, type=\"response\")\n",
    "predlogit <- prediction(roclogit, datestq[, \"DepSeuil\"])\n",
    "perflogit <- performance(predlogit, \"tpr\", \"fpr\")\n",
    "\n",
    "\n",
    "rocnnetr=pred.nnetr/300\n",
    "prednnetr=prediction(rocnnetr,datestq$DepSeuil)\n",
    "perfnnetr=performance(prednnetr,\"tpr\",\"fpr\")\n",
    "\n",
    "rocnnetq=pred.nnetq\n",
    "prednnetq=prediction(rocnnetq,datestq$DepSeuil)\n",
    "perfnnetq=performance(prednnetq,\"tpr\",\"fpr\")\n",
    "\n",
    "# tracer les courbes ROC en les superposant pour mieux comparer\n",
    "plot(perflogit,col=\"blue\")\n",
    "plot(perfnnetr,col=\"darkgreen\",lty=2,add=TRUE) \n",
    "plot(perfnnetq,col=\"darkgreen\",add=TRUE)  \n",
    "legend(\"right\", legend=c(\"Logit\", \"Nnetr\", \"Nnetq\"),\n",
    "       col=c(\"blue\",\"darkgreen\", \"darkgreen\"), lty=c(1,2,1), text.font=1,    cex=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Une méthode semble-t-elle significativement meilleure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <FONT COLOR=\"Red\"> Épisode 5 :  Industrialisation de l'apprentissage </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Un avantage de R est le nombre considérable d'utilisateurs qui participent au développement des librairies. Cet avantage a un revers: le manque d'homogénéité de celles-ci. Pour y remédier dans les applications d'apprentissage machine, la (méta)librairie [`caret`](https://topepo.github.io/caret/) de [Max Kuhn (2008)](https://www.jstatsoft.org/article/view/v028i05) intègre dans un même usage, une même syntaxe, l'ensemble des fonctionnalités d'apprentissage et propose une approche unifiée des procédures d'optimisation des paramètres.\n",
    "\n",
    "Les instructions suivantes reprennent rapidement les étapes précédentes afin d'introduire l'usage de `caret`. Elles se limitent à l'objectif de prévision de dépassement du seuil (classification). Le code pour modéliser la concentration par régression s'en déduit facilement.\n",
    "\n",
    "### Calcul parallèle\n",
    "Par ailleurs, même sous windows, `caret` offre simplement des possibilités de parallélisation en utilisant la package `doParallel`. Même si les algorithmes des différentes méthodes d'apprentissage ne sont pas parallélisés, les itérations des calculs de validation croisée pour l'optimisation des paramètres sont effectivement parallélisés avec un gain de temps très appréciable fonction du nombre de processeurs. Ceci est obtenu en exécutant les commandes suivantes en supposant que 4 processeurs sont disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:46.232486Z",
     "start_time": "2019-11-18T09:22:23.827Z"
    }
   },
   "outputs": [],
   "source": [
    "library(doParallel)\n",
    "cl <- makeCluster(4)\n",
    "registerDoParallel(cl) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des données\n",
    "Les données considérées sont les données initiales et la stratégie adoptée pour optimiser les modèles est la validation croisée. D’autres choix sont possibles (bootstrap). La librairie `caret` intègre des fonctions d’échantillonnage et de normalisation des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:46.260767Z",
     "start_time": "2019-11-18T09:22:24.051Z"
    }
   },
   "outputs": [],
   "source": [
    "summary(ozone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:47.233193Z",
     "start_time": "2019-11-18T09:22:24.058Z"
    }
   },
   "outputs": [],
   "source": [
    "library(caret)\n",
    "# extraction des données\n",
    "# Variable cible\n",
    "Y=ozone[,\"DepSeuil\"]\n",
    "# Variables explicatives\n",
    "X=ozone[,-c(2,11)]\n",
    "# Transformation des facteurs en indicatrices pour utiliser certains algorithmes\n",
    "# notamment xgboost\n",
    "library(FactoMineR)\n",
    "X=data.frame(tab.disjonctif(X[,c(1,4)]),X[,-c(1,4)])\n",
    "summary(Y);summary(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??caret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:47.393572Z",
     "start_time": "2019-11-18T09:22:24.065Z"
    }
   },
   "outputs": [],
   "source": [
    "# indices de l’échantillon d’apprentissage\n",
    "xx=11 # Changer cette valeur pour personnaliser l'échantillonnage\n",
    "set.seed(xx)\n",
    "inTrain = createDataPartition(X[,1],p = 0.8, list = FALSE)\n",
    "# Extraction des échantillons\n",
    "trainDescr=X[inTrain,]\n",
    "testDescr=X[-inTrain,]\n",
    "testY=Y[-inTrain]\n",
    "trainY=Y[inTrain]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certaines méthodes sont sensibles à des effets de variance ou d'unité des variables. Il est préférable d'introduire une normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:47.433813Z",
     "start_time": "2019-11-18T09:22:24.296Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalisation calculée sur les paramètres de l'échantillon d'apprentissage\n",
    "xTrans=preProcess(trainDescr)\n",
    "trainDescr=predict(xTrans,trainDescr)\n",
    "# Puis appliquée également à l'échantillon test\n",
    "testDescr=predict(xTrans,testDescr)\n",
    "# Choix de la validation croisée\n",
    "cvControl=trainControl(method=\"cv\",number=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation des modèles\n",
    "La librairie intègre beaucoup de modèles ou méthodes (233!) et celles qui sont sélectionnées ci-dessous font partie des plus utilisées. Consultez  la   [liste   des   méthodes](http://topepo.github.io/caret/available-models.html)   disponibles   en option   de   la   fonction: `train`.  Le choix est en principe limité également aux méthodes acceptant des variables quantitatives et qualitatives mais, en transformant préalablement les variables qualitatives en paquets d'indicatrices (*dummies*) les autres méthodes sont accessibles. Exécutez chaque bloc de commandes pour tracer séparemment chacun des graphes afin de contrôler le bon comportement\n",
    "de l’optimisation du paramètre de complexité de chaque modèle.\n",
    "\n",
    "L'automatisation  de l'optimisation  de  certaines méthodes comme  la régression logistique est moins flexible qu’en utilisation  \"manuelle\"; en particulier pour le choix de l’algorithme de sélection de variables. Il faut se montrer (très) patient pour certaines optimisations alors que d'autres sont immédiates, voire inutiles. \n",
    "\n",
    "Le paramètre `tuneLength` caractérise  un \"effort\" d'optimisation, c'est en gros le nombre de valeurs de paramètres testées sur une grille fixée automatiquement. En prenant plus de soin et aussi plus de temps, il est possible de fixer précisément des grilles pour les valeurs du ou des paramètres optimisés pour chaque méthode. L'approche sommaire de `caret` s'avère souvent suffisante et l'optimisation d'un modèle, de sa complexité et peut être affinée après sélection de la méthode.\n",
    "\n",
    "**Question** Pour chaque cas, identifiez la méthode, précisez les paramètres associés et notez celui ou ceux optimisés par défaut par `caret`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:53.674471Z",
     "start_time": "2019-11-18T09:22:24.529Z"
    }
   },
   "outputs": [],
   "source": [
    "#1 Régression logistique\n",
    "# Attention, la régression logistique sans interaction (linéaire) est estimée ci-dessous\n",
    "set.seed(2)\n",
    "rlogFit = train(trainDescr, trainY,method = \"glmStepAIC\", tuneLength = 10,\n",
    "                trControl = cvControl, trace=FALSE)\n",
    "rlogFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:54.874252Z",
     "start_time": "2019-11-18T09:22:24.537Z"
    }
   },
   "outputs": [],
   "source": [
    "#2 Arbre de décision\n",
    "set.seed(2)\n",
    "rpartFit = train(trainDescr, trainY, method = \"rpart\", tuneLength = 10,\n",
    "    trControl = cvControl)\n",
    "rpartFit\n",
    "plot(rpartFit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:26:06.838240Z",
     "start_time": "2019-11-18T09:22:24.544Z"
    }
   },
   "outputs": [],
   "source": [
    "#3 Réseau de neurones\n",
    "set.seed(2)\n",
    "nnetFit = train(trainDescr, trainY, method = \"nnet\", tuneLength = 6,\n",
    "                trControl = cvControl, trace=FALSE)\n",
    "nnetFit\n",
    "plot(nnetFit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:26:19.223823Z",
     "start_time": "2019-11-18T09:22:24.551Z"
    }
   },
   "outputs": [],
   "source": [
    "#4 Random forest\n",
    "set.seed(2)\n",
    "rfFit = train(trainDescr, trainY,method = \"rf\", tuneLength = 8,\n",
    "              trControl = cvControl, trace=FALSE)\n",
    "rfFit\n",
    "plot(rfFit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:26:28.217758Z",
     "start_time": "2019-11-18T09:22:24.558Z"
    }
   },
   "outputs": [],
   "source": [
    "#5 Boosting \n",
    "set.seed(2)\n",
    "gbmFit = train(trainDescr, trainY,method = \"gbm\", tuneLength = 8,\n",
    "               trControl = cvControl)\n",
    "gbmFit\n",
    "plot(gbmFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme l'algoritme *extreme gradient boosting* (approximation du gradient par décomposition de Taylor et parallélisation des codes) est très présent dans les solutions des concours *Kaggle* celui-ci est testé. *Attention*, les bons résultats des concours sont obtenus au prix d'une lourde et complexe procédure d'optimisation des nombreux paramètres de cette approche; procédure rendue possible par la parallélisation avancée de la librairie [`xgboost`](https://xgboost.readthedocs.io/en/latest/) et l'utilisation de cartes graphiques (GPU). Si cet environnement n'est pas disponible l'optimisation est assez longue, même avec la parallélisation sur 4 processeurs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:24.804Z"
    }
   },
   "outputs": [],
   "source": [
    "#6 Extrême gradient boosting\n",
    "library(xgboost)\n",
    "set.seed(2)\n",
    "xgbFit = train(trainDescr, trainY,method = \"xgbTree\", tuneLength = 6,\n",
    "               trControl = cvControl, trace=FALSE)\n",
    "xgbFit\n",
    "plot(xgbFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prévision et erreur de test\n",
    "Les méthodes sélectionnées et optimisées sont ensuite appliquées à la prévision de l’échantillon test. Estimation du taux de bien classés:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:25.049Z"
    }
   },
   "outputs": [],
   "source": [
    "models=list(logit=rlogFit,cart=rpartFit,nnet=nnetFit,rf=rfFit,gbm=gbmFit,xgb=xgbFit)\n",
    "testPred=predict(models, newdata = testDescr)\n",
    "# taux de bien classés\n",
    "lapply(testPred,function(x)mean(x==testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracé  des  courbes  ROC  pour  analyser  la spécificité  et  la sensibilité  des  différentes  méthodes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:25.288Z"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 10, repr.plot.height = 8)\n",
    "\n",
    "models=list(logit=rlogFit,cart=rpartFit,nnet=nnetFit,rf=rfFit,gbm=gbmFit,xgb=xgbFit)\n",
    "testProb=predict(models, newdata = testDescr,type=\"prob\")\n",
    "predroc=lapply(testProb,function(x)prediction(x[,1],testY==FALSE))\n",
    "perfroc=lapply(predroc,\n",
    "function(x)performance(x, \"tpr\", \"fpr\"))\n",
    "plot(perfroc$logit,col=1)\n",
    "plot(perfroc$cart,col=2,add=TRUE)\n",
    "plot(perfroc$nnet,col=3,add=TRUE)\n",
    "plot(perfroc$rf,col=4,add=TRUE)\n",
    "plot(perfroc$gbm,col=5,add=TRUE)\n",
    "plot(perfroc$xgb,col=6,add=TRUE)\n",
    "legend(\"bottomright\",legend=c(\"logit\",\"CART\",\"nnet\",\"RF\",\"boost\",\"xgBoost\"),col=c(1:6),pch=\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Validation croisée *Monte Carlo*](http://wikistat.fr/pdf/st-m-app-risque-estim.pdf)\n",
    "L'échantillon est de faible taille (#200), et les estimations des taux de bien classés comme le tracé des courbes ROC sont très dépendants de l’échantillon test; on peut s’interroger sur l’identité du modèle le plus performant ainsi que sur la significativité des différences observées entre les méthodes. Il est donc important d’itérer le processus (validation croisée *Monte Carlo*) sur plusieurs échantillons tests. \n",
    "\n",
    "**Question** Exécutez la fonction en annexe en choisissant les méthodes semblant les plus performantes. Attention au temps de calcul ! CART peut performant est supprimé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:25.551Z"
    }
   },
   "outputs": [],
   "source": [
    "# Choisir la liste des méthodes et l’effort d’optimisation\n",
    "models=c(\"gbm\",\"rf\",\"nnet\",\"glmStepAIC\",\"xgbTree\")\n",
    "noptim=c(6,6,6,6,6)\n",
    "# Initialiser le générateur et fixer le nombre d’itérations\n",
    "# Changer ces valeurs. Attention au temps de calcul! Être patient!\n",
    "Niter=10 ; Init=11  \n",
    "# Appel de la fonction définie en annexe\n",
    "pred.ozone=pred.autom(X,Y,methodes=models,N=Niter,xinit=Init,size=noptim,type=\"prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:25.800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calcul des taux de bien classés\n",
    "obs=pred.ozone$obs\n",
    "prev.ozone=pred.ozone$pred\n",
    "res.ozone=lapply(prev.ozone,function(x)apply((x>0.5)==(obs==1),2,mean))\n",
    "# Moyennes des taux de bien classés par méthode\n",
    "lapply(res.ozone,mean)\n",
    "# distributions des taux de bien classés\n",
    "boxplot(data.frame(res.ozone))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les commandes suivantes tracent les courbes ROC moyennes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:26.055Z"
    }
   },
   "outputs": [],
   "source": [
    "## Comparaison des méthodes par le\n",
    "# tracé des courbes ROC moyennes\n",
    "#\n",
    "predroc.ozone=lapply(prev.ozone,function(x)prediction(x,obs==1))\n",
    "perfroc.ozone=lapply(predroc.ozone,function(x)performance(x,\"tpr\",\"fpr\"))\n",
    "plot(perfroc.ozone$gbm,col=1,lwd=2,avg=\"vertical\")\n",
    "plot(perfroc.ozone$rf,col=2,add=TRUE,lwd=2,avg=\"vertical\")\n",
    "plot(perfroc.ozone$nnet,add=TRUE,col=3,lwd=1.5,avg=\"vertical\")\n",
    "plot(perfroc.ozone$xgbTree,add=TRUE,col=4,lwd=1.5,avg=\"vertical\")\n",
    "plot(perfroc.ozone$glmStepAIC,add=TRUE,col=5,lwd=1.5,avg=\"vertical\")\n",
    "legend(\"bottomright\",legend=c(\"boost\",\"RF\", \"nnet\",\"xgBoost\",\"logit\"),col=c(1:5),pch=\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Quelle méthode retenir, en fonction du taux de faux positifs acceptable, pour prévoir le dépassement du seuil? Et si le commanditaire veut une solution explicable?\n",
    "\n",
    "La même démarche réalisée sur la prévision de concentration avant de prédire le dépassement du seuil conduit à des résultats similaires. \n",
    "\n",
    "*N.B.* \n",
    "* Ce n'est pas la régression logistique avec interactions (quadratique) qui a été testée dans cette dernière comparaison.\n",
    "* L'algorithme xgboost nécessiterait des efforts plus importants d'optimisation des paramètres mais le coût de calcul s'en ressent. A tester en Python avec un accès à une carte GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <FONT COLOR=\"Red\">Épisode 6 : Gestion des données manquantes </font>\n",
    "**Remarque** Il est possible d'exécuter directement l'*épisode 6* sans passer par toutes les étapes de classification supervisée. Il suffit d'exécuter les *sections 2 et 3* de l'*épisode 1*, phase exploratoire, afin de construire les données utilisées dans les sections 13 et 14 d'imputation des données manquantes et de détection d'atypiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Gestion des données manquantes](http://wikistat.fr/pdf/st-m-app-idm.pdf)\n",
    "\n",
    "Les vraies données sont le plus souvent mitées par l'absence de données, conséquence d'erreurs de saisie, de pannes de capteurs... Les librairies de R offrent de très nombreux choix pour faire des imputations de données manquantes quand celles-ci le sont de façon complètement aléatoire. \n",
    "\n",
    "Plusieurs stratégies sont exécutées et comparées après avoir généré aléatoirement un pourcentage de défaillances (trous) dans les valeurs des variables explicatives.\n",
    "\n",
    "**Question** Pourquoi la structure des variables explicatives incite-t-elle à exécuter l'algorithme missForest de la librairie éponyme? \n",
    "\n",
    "**Dans un premier temps**, nous allons comparer quelques méthodes d'imputation sur les données explicatives quantitatives : LOCF, imputation par la moyenne ou la médiane, kNN, MissForest et Amelia II.\n",
    "\n",
    "\n",
    "**Dans un deuxième temps**, nous nous concentrerons sur la méthode Missforest et l'objectif sera d'étudier l'impact de l'imputation des données sur les performances de classification pour prédire la variable \"depassement de seuil\" en comparant deux stratégies :\n",
    "\n",
    "\n",
    "La **première stratégie** commence par imputer les données manquantes en les prévoyant par l'algorithme MissForest. \n",
    "\n",
    "Une fois les données manquantes imputées, différentes méthodes de prévision sont utilisables comme précédemment. Deux sont exécutées: forêts aléatoires et *extrem gradient boosting*.\n",
    "\n",
    "La **deuxième stratégie** évite l'étape d'imputation en exécutant directement un algorithme de prévision tolérant des données manquantes. Peu d'algorithmesle font, c'est le cas de `XGBoost`.\n",
    "\n",
    "Attention, les commandes ci-dessous font appel à de nombreux fichiers qu'il est facile de mélanger.\n",
    "- `X` données complètes initiales et `Xd` la version où les variables qualitatives sont remplacées par des indicatrices, \n",
    "- `Xna` les données avec des trous, `Xdna` la version avec indicatrices,\n",
    "\n",
    "- `XnaImp` les données avec imputations et `XdnaImp` la version avec indicatrices.\n",
    "\n",
    "Le remplacement des variables qualitatives par des variables indicatrices est imposé par l'utilisation de la librairie `XGBoost` et cela ne change en rien les résultats des forêts aléatoires.\n",
    "\n",
    "### Préparation des trous dans `ozone`\n",
    "Les données initiales de la base `ozone` sont reprises. Seule la variable à expliquer de dépassement de seuil est conservée. La librairie `missForest`propose une fonction pour générer un pourcentage fixé a priori de données manquantes dans une base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:26.834Z"
    }
   },
   "outputs": [],
   "source": [
    "# Variable cible\n",
    "Y=ozone[,\"DepSeuil\"]\n",
    "# Variables explicatives\n",
    "X=ozone[,-c(2,11)]\n",
    "n=nrow(X); p=ncol(X)\n",
    "summary(Y); summary(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:26.842Z"
    }
   },
   "outputs": [],
   "source": [
    "library(missForest)\n",
    "# faire une proportion tauxNA de trous aléatoires dans X\n",
    "# Données missing at random\n",
    "tauxNa=0.2\n",
    "set.seed(11)\n",
    "Xna=prodNA(X,tauxNa)\n",
    "summary(Xna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Quel est en moyenne le nombre de données manquantes par colonne?\n",
    "\n",
    "### Comparaison de méthodes d'imputation sur données quantitatives ###\n",
    "\n",
    "On conserve seulement les variables quantitatives pour comparer diverses méthodes d'imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tableau des données quantitatives\n",
    "#On compare les différentes méthodes de complétion sur la variable Temperature\n",
    "\n",
    "Xnaquanti=Xna[,-c(1,4)]\n",
    "Xquanti=X[,-c(1,4)]\n",
    "ind.na=which(is.na(Xnaquanti),arr.ind=TRUE)\n",
    "ind.na.Temp=which(is.na(Xnaquanti[,2]),arr.ind=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complétion par la dernière valeur connue (LOCF) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(zoo) # chargement de la bibliothèque\n",
    "X.locf=na.locf(Xnaquanti,na.rm=FALSE)\n",
    "X.locf=na.locf(X.locf,na.rm=FALSE,fromLast=TRUE) # dans l'autre sens\n",
    "err.locf=(Xquanti-X.locf)[ind.na.Temp,2]\n",
    "boxplot(err.locf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complétion par la moyenne ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moy=apply(Xnaquanti,2,mean,na.rm=TRUE)\n",
    "X.moy=Xnaquanti\n",
    "ind.na=which(is.na(X.moy),arr.ind=TRUE)\n",
    "X.moy[ind.na]=moy[ind.na[,2]]\n",
    "err.moy=(Xquanti-X.moy)[ind.na.Temp,2]\n",
    "boxplot(data.frame(err.locf,err.moy),ylim=c(-15,15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complétion par la mediane ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "med=apply(Xnaquanti,2,median,na.rm=TRUE)\n",
    "X.med=Xnaquanti\n",
    "ind.na=which(is.na(X.med),arr.ind=TRUE)\n",
    "X.med[ind.na]=med[ind.na[,2]]\n",
    "err.med=(Xquanti-X.med)[ind.na.Temp,2]\n",
    "\n",
    "boxplot(data.frame(err.locf,err.moy,err.med),ylim=c(-15,15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complétion par k plus proches voisins (kNN) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(VIM) # chargement de la bibliothèque\n",
    "X.kNN=kNN(Xnaquanti, k=5, imp_var=FALSE)\n",
    "err.kNN=(Xquanti-X.kNN)[ind.na.Temp,2]\n",
    "boxplot(data.frame(err.locf,err.moy,err.med,err.kNN),ylim=c(-15,15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complétion avec Missforest ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X.mf=missForest(Xnaquanti,xtrue=Xquanti)\n",
    "err.mf=(Xquanti-X.mf$ximp)[ind.na.Temp,2]\n",
    "boxplot(data.frame(err.locf,err.moy,err.med,err.kNN,err.mf),ylim=c(-15,15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Completion avec Amelia II ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(Amelia) # chargement de la bibliothèque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.amelia=amelia(Xnaquanti,m=1)$imputations$imp1\n",
    "err.amelia=(Xquanti-X.amelia)[ind.na.Temp,2]\n",
    "boxplot(data.frame(err.locf,err.moy,err.med,err.kNN,err.mf,err.amelia),ylim=c(-15,15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Que concluez vous ? Quelle méthode vous semble la plus pertinente sur ces données ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation avec MissForest et impact sur la classification ###\n",
    "\n",
    "On reprend ici le jeu de données complet, incluant les variables explicatives quantitatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connaissant les \"vraies\" données initiales, il est possible, dans ce cas de calculer des erreurs d'imputation de `missForest`.\n",
    "\n",
    "**Question** Quelles sont elles? Quelle estimation de l'erreur est fournie quand les données manquantes le sont vraiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(missForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:27.103Z"
    }
   },
   "outputs": [],
   "source": [
    "XnaImp=missForest(Xna,xtrue=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:27.111Z"
    }
   },
   "outputs": [],
   "source": [
    "XnaImp$OOBerror;XnaImp$error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifiez que les imputations sont réalisées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:27.381Z"
    }
   },
   "outputs": [],
   "source": [
    "summary(XnaImp$ximp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme précédemment, l'utilisation de `XGBoost` impose de transformer les facteurs en indicatrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:27.648Z"
    }
   },
   "outputs": [],
   "source": [
    "library(FactoMineR)\n",
    "# données complètes\n",
    "Xd=data.frame(tab.disjonctif(X[,c(1,4)]),X[,-c(1,4)])\n",
    "# données avec trous\n",
    "Xdna=data.frame(tab.disjonctif(Xna[,c(1,4)]),Xna[,-c(1,4)]) \n",
    "# données avec imputations\n",
    "XdnaImp=data.frame(tab.disjonctif(XnaImp$ximp[,c(1,4)]),XnaImp$ximp[,-c(1,4)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librairie `caret` facilite beaucoup la syntaxe pour l'exécution de `xgboost`, elle est donc reprise. Il faudrait sinon transformer les données sous un autre format. C'est intégré par `caret`.\n",
    "\n",
    "Construction des mêmes échantillons d'apprentissage et de test dans les trois cas: données initiales, manquantes, imputées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:27.913Z"
    }
   },
   "outputs": [],
   "source": [
    "library(caret)\n",
    "# parallélisation\n",
    "library(doParallel)\n",
    "cl <- makeCluster(4)\n",
    "registerDoParallel(cl) \n",
    "# indices de l’échantillon d’apprentissage\n",
    "xx=11 # Changer cette valeur pour personnaliser l'échantillonnage\n",
    "set.seed(xx)\n",
    "inTrain = createDataPartition(X[,1],p = 0.8, list = FALSE)\n",
    "# Extraction des échantillons\n",
    "trainDescr=Xd[inTrain,]\n",
    "testDescr=Xd[-inTrain,]\n",
    "# Les mêmes avec trous\n",
    "trainDescrNA=Xdna[inTrain,]\n",
    "testDescrNA=Xdna[-inTrain,]\n",
    "# Les mêmes avec données manquantes imputées\n",
    "trainDescrNAimp=XdnaImp[inTrain,]\n",
    "testDescrNAimp=XdnaImp[-inTrain,]\n",
    "testY=Y[-inTrain]\n",
    "trainY=Y[inTrain]\n",
    "cvControl=trainControl(method=\"cv\",number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:27.921Z"
    }
   },
   "outputs": [],
   "source": [
    "# prévision avec random forest sur données initiales\n",
    "set.seed(2)\n",
    "rfFit = train(trainDescr, trainY,method = \"rf\", tuneLength = 8,\n",
    "              trControl = cvControl, trace=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:27.928Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prévision avec XGBoost sur données initiales\n",
    "\n",
    "set.seed(2)\n",
    "xgbFit = train(trainDescr, trainY,method = \"xgbTree\", tuneLength = 6,\n",
    "               trControl = cvControl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pendant que `XGBoost` tourne, réviser les [principes de cet algorithme](http://wikistat.fr/pdf/st-m-app-agreg.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:28.205Z"
    }
   },
   "outputs": [],
   "source": [
    "# erreur de prévision sur le test avec données initiales\n",
    "models=list(rf=rfFit,xgb=xgbFit)\n",
    "#models=list(rf=rfFit)\n",
    "testPred=predict(models, newdata = testDescr)\n",
    "# taux de bien classés\n",
    "lapply(testPred,function(x)mean(x==testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:28.212Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prévision avec random forest sur données imputées\n",
    "set.seed(2)\n",
    "rfFitNAimp = train(trainDescrNAimp, trainY,method = \"rf\", tuneLength = 8,\n",
    "              trControl = cvControl, trace=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:28.220Z"
    }
   },
   "outputs": [],
   "source": [
    " #Prévision avec XGBoost sur données imputées\n",
    "\n",
    "xgbFitNAimp = train(trainDescrNAimp, trainY,method = \"xgbTree\", tuneLength = 6,\n",
    "               trControl = cvControl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pendant que `XGBoost` tourne, réviser les [principes de missForest](http://wikistat.fr/pdf/st-m-app-idm.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:28.506Z"
    }
   },
   "outputs": [],
   "source": [
    "# erreur de prévision sur le test avec données imputées\n",
    "\n",
    "models=list(rfNAimp=rfFitNAimp,xgbNAimp=xgbFitNAimp)\n",
    "\n",
    "#models=list(rfNAimp=rfFitNAimp)\n",
    "testPred=predict(models, newdata = testDescrNAimp)\n",
    "# taux de bien classés\n",
    "lapply(testPred,function(x)mean(x==testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Qu'en déduisez vous sur la qualité des résultats après imputation ? Augmentez le taux de données manquantes pour voir l'impact de ce taux sur la qualité de prédiction. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prévision sans imputation \n",
    "\n",
    "La phase d'imputation est rendue obligatoire par l'usage de nombreuses méthodes qui n'acceptent pas les données manquantes. Il peut être intéressant de s'en passer car les informations reconstruites ne sont pas utilisables à d'autres fins; `XGBoost` offre cette oppotunité. Pendant qu'il tourne, [essayer de comprendre](https://arxiv.org/abs/1603.02754) les astuces mises en oeuvre pour tolérer des données manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:28.785Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prévision avec XGBoost avec données manquantes\n",
    "\n",
    "xgbFitNA = train(trainDescrNA, trainY,method = \"xgbTree\", tuneLength = 6,\n",
    "               trControl = cvControl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:28.793Z"
    }
   },
   "outputs": [],
   "source": [
    "# Erreur de prévision avec XGBoot tolérant les données manquantes.\n",
    "testPred=predict(xgbFitNA, newdata = testDescrNA)\n",
    "mean(testPred==testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Comparer les résultats obtenus par les différents stratégies. En tenant compte des temps de calcul, laquelle semble la plus efficace sur ces données. \n",
    "\n",
    "*NB* L'utilisation avancée de `XGBoost` nécessite plus de puissance de calcul afin d'affiner le réglage des nombreux paramètres.\n",
    "\n",
    "**Question** Qu'en serait-il en utlisant Python au lieu de R?\n",
    "\n",
    "**FIN DU TP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <FONT COLOR=\"Red\">Épisode 7 : Détection d'observations atypiques ou anomalies  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La détection d'observations *atypiques*, *anomalies* ou *outliers* nommée également *OCC* (*One Class Classification*) ou *novelty detection* est source d'une très abondante bibliographie; voir par exemple [Aggarwal 2016](http://www.charuaggarwal.net/outlierbook.pdf). A ne pas confondre avec les modèles de *valeurs extrêmes*, les valeurs atypiques dans le cas unidimensionnel sont généralement traitées en référence à des modèles paramétriques: Gaussien ou autre, qui caractérisent la \"normalité\". Systématiquement et également dans le cas multidimensionnel, la notion d'anomalie est définie relativement à un modèle et sous le contrôle d'un paramètre à \"régler\". Le modèle est paramétrique ou non, local ou global. Par exemple, dans le cas du modèle linéaire, la distance de Cook est un indicateur de points influents ou atypiques par rapport au modèle.\n",
    "\n",
    "R propose quelques librairies et fonctions de détection d'atypiques. \n",
    "- [`outliers`](https://cran.r-project.org/web/packages/outliers/outliers.pdf) propose un ensemble de tests univariés.\n",
    "- [`Rlof`]() propose une version parallélisée du calcul du score LOF (*Local Factor Outlier*). Une estimation locale de la densité en un point est comparée à celle de ses voisins. \n",
    "- [`dbscan`](https://cran.r-project.org/web/packages/dbscan/dbscan.pdf) propose en plus d'algorihtmes de classification non-supervisée originaux, le calcul de `glosh` (*Global-Local Outlier Score from Hierarchies*).\n",
    "- [`kernlab`](http://ftp.auckland.ac.nz/software/CRAN/doc/vignettes/kernlab/kernlab.pdf) propose une option de *One Class Classification SVM* qui cherche à séparer l'origine de l'ensemble des points; `e1071`le propose aussi mais avec des problèmes d'exécution!\n",
    "- [`randomForest`](https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#micro7) estime, dans le cas supervisé lorsque une variable explicative est connue, une notion de \"distance\" de chaque point avec ses voisins en considérant les co-appartenances des points aux mêmes feuilles des arbres. Dans le cas contraire, comme pour la situation d'OCC, une approche non supervisée consiste à générer tout un ensemble d' observations atypiques avant de construire un modèle prédisant pour chaque observation la variable échantillon initiale *vs.* atypique simulé. La notion précédente de \"distance\" est à nouveau utilisée comme score d'atypicité.\n",
    "\n",
    "Quelques cas sont considérés ici.\n",
    "\n",
    "Ce traitement intervient dans ce tutoriel avec une finalité essentiellement pédagogique. Il n'est pas indispensale sur ces données, relativement cohérentes alors que l'objectif poursuivi n'est pas la recherche d'une défaillance contrairement à une situation du domaine industriel: suivi de fabrication ou de fonctionnement. \n",
    "\n",
    "Néanmoins, sur tout jeu de données, l'étape préalable exploratoire peut inclure la recherche d'observations atypiques multidimensionnelles qui permettraient d'identifier des incohérences de mesures en complément des études unidimensionnelles de la première partie.\n",
    "\n",
    "Considérons quatre approches suivant des principes très différents parmi bien d'autres. Elles vont permettre d'identifier des observations atypiques avant de les représenter en utilisant l'ACP.\n",
    "### *Local Outlier Factor*\n",
    "Les données sont restreintes aux seules variables quantitatives explicatives.\n",
    "\n",
    "**Question** Quel est le rôle du paramètre *k* ci-dessous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:29.355Z"
    }
   },
   "outputs": [],
   "source": [
    "library(Rlof)\n",
    "ozoneR=ozone[,-c(1,2,5,11)]\n",
    "atypLof=lof(ozoneR,k=c(3:7),cores=3)\n",
    "options(repr.plot.width=8, repr.plot.height=6)\n",
    "boxplot(atypLof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:29.362Z"
    }
   },
   "outputs": [],
   "source": [
    "table(atypLof[,1]>1.5,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Comment intervient la borne 1.5? A quelle classe appartiennent majoritairement les observations jugées atypiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:29.650Z"
    }
   },
   "outputs": [],
   "source": [
    "atypLofInd=which(atypLof[,1]>1.5)\n",
    "coul=as.integer(ozone[,\"DepSeuil\"])+2\n",
    "taille=rep(0.5,length(coul))\n",
    "acp=princomp(ozoneR,cor=TRUE)\n",
    "options(repr.plot.width=6, repr.plot.height=6)\n",
    "coul[atypLofInd]=2\n",
    "taille[atypLofInd]=.8\n",
    "plot(acp$scores,col=coul, pch=17+coul-2,cex=taille)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Que dire de la localisation des observations atypiques dans le plan de l'ACP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Global-Local Outlier Score from Hierarchies* \n",
    "Les scores proches de 1 signalent des atypiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:30.220Z"
    }
   },
   "outputs": [],
   "source": [
    "library(dbscan)\n",
    "atypGlosh=glosh(as.matrix(ozoneR),k=3)\n",
    "options(repr.plot.width=4, repr.plot.height=6)\n",
    "boxplot(atypGlosh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:30.226Z"
    }
   },
   "outputs": [],
   "source": [
    "table(atypLof[,1]>1.5,atypGlosh>0.82)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Que dire de ces deux critères?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:30.528Z"
    }
   },
   "outputs": [],
   "source": [
    "atypGloshInd=which(atypGlosh>0.82)\n",
    "coul=as.integer(ozone[,\"DepSeuil\"])+2\n",
    "taille=rep(0.5,length(coul))\n",
    "coul[atypGloshInd]=2; taille[atypGloshInd]=.8\n",
    "options(repr.plot.width=6, repr.plot.height=6)\n",
    "plot(acp$scores,col=coul, pch=17+coul-2,cex=taille)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *One Class Classification SVM*\n",
    "**Question** Quel est le rôle du paramètre `nu`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:30.828Z"
    }
   },
   "outputs": [],
   "source": [
    "library(kernlab)\n",
    "ozoneOcc=ksvm(x=as.matrix(ozoneR),y=NULL,type=\"one-svc\",\n",
    "              kernel=\"rbfdot\",nu = 0.005)\n",
    "atypOcc=!fitted(ozoneOcc)\n",
    "ozoneOcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:30.835Z"
    }
   },
   "outputs": [],
   "source": [
    "coul=as.integer(ozone[,\"DepSeuil\"])+2\n",
    "taille=rep(.5,length(coul))\n",
    "options(repr.plot.width=6, repr.plot.height=6)\n",
    "coul[atypOcc]=2\n",
    "taille[atypOcc]=0.8\n",
    "plot(acp$scores,col=coul, pch=17+coul-2,cex=taille)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Même question sur la répartition des observations atypiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:31.130Z"
    }
   },
   "outputs": [],
   "source": [
    "table(atypLof[,1]>1.5,atypOcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Comment interpréter la table ci-dessus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomalies au sens de *random forest*\n",
    "#### Cas supervisé\n",
    "La première approche prend en compte la variable explicative et considère donc les observations les plus en marge du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:31.742Z"
    }
   },
   "outputs": [],
   "source": [
    "library(randomForest)\n",
    "Y=ozone[,11]\n",
    "X=ozone[,-c(2,11)]\n",
    "ozoneRF=randomForest(X,Y,proximity=TRUE)\n",
    "atypRF=outlier(ozoneRF)\n",
    "options(repr.plot.width=4, repr.plot.height=6)\n",
    "boxplot(atypRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atypRFInd=which(atypRF>20)\n",
    "coul=as.numeric(Y)+2\n",
    "options(repr.plot.width=8, repr.plot.height=6)\n",
    "plot(atypRF,type=\"h\",col=coul)\n",
    "legend(\"topright\",legend=levels(Y),text.col=c(3:4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(atypRF>20,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Que dire de la répartition des atypiques par rapport à la variable de dépassement de seuil ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coul=as.integer(ozone[,\"DepSeuil\"])+2\n",
    "taille=rep(.5,length(coul))\n",
    "acp=princomp(ozoneR,cor=TRUE)\n",
    "options(repr.plot.width=6, repr.plot.height=6)\n",
    "coul[atypRFInd]=2\n",
    "taille[atypRFInd]=.8\n",
    "plot(acp$scores,col=coul, pch=17+coul-2,cex=taille)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Commenter la répartition des atypiques au sens de **Random Forest**. Serait-il raisonnable de supprimer ces observations ?\n",
    "\n",
    "**Remarque** Si la variable à expliquer *$Y$* est telle que l'on soupçonne de possibles erreurs de labels, cela peut être une façon de les détecter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cas non-supervisé\n",
    "Moins connue, Breiman a proposé une version [non-supervisée](https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#unsup) de randomForest. Elle fournit *in fine* le même type de critère mais sans faire intervenir *$Y$*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(11)\n",
    "ozoneURF <- randomForest(x=ozoneR,y=NULL,proximity=TRUE)\n",
    "atypURF=outlier(ozoneURF)\n",
    "options(repr.plot.width=4, repr.plot.height=6)\n",
    "boxplot(atypURF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atypURFInd=which(atypURF>2.5)\n",
    "coul=as.numeric(Y)+2\n",
    "options(repr.plot.width=8, repr.plot.height=6)\n",
    "plot(atypURF,type=\"h\",col=coul)\n",
    "legend(\"topright\",legend=levels(Y),text.col=c(3:4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coul=as.integer(ozone[,\"DepSeuil\"])+2\n",
    "taille=rep(.5,length(coul))\n",
    "options(repr.plot.width=6, repr.plot.height=6)\n",
    "coul[atypURFInd]=2\n",
    "taille[atypURFInd]=.8\n",
    "plot(acp$scores,col=coul, pch=17+coul-2,cex=taille)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(atypURF>2.5,atypLof[,1]>1.5)\n",
    "table(atypURF>2.5,atypOcc)\n",
    "table(atypLof[,1]>1.5,atypURF>2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Que dire sur la correspondance entre les trois stratégies de détection d'observations atypiques?\n",
    "\n",
    "**Question** Qu'est-ce qui permettrait d'en choisir une parmi les trois ou parmi les très nombreuses autres méthodes disponibles dans la littérature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Annexe: Fonction de validation croisée *Monte Carlo*\n",
    "*N* réplications des estimations / prévisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.autom=function(X,Y,p=1/2,methodes=c(\"knn\",\n",
    "\"rf\"),size=c(10,2),xinit=11,N=10,typerr=\"cv\",\n",
    "number=4,type=\"raw\") {\n",
    "# Fonction de prévision de N échantillons tests\n",
    "# par une liste de méthodes de régression\n",
    "# ou classification (uniquement 2 classes)\n",
    "# Optimisation des paramètres par validation\n",
    "# croisée (défaut) ou bootstrap ou... (cf. caret)\n",
    "# X : matrice ou frame des variables explicatives\n",
    "# Y : variable cible quantitative ou qualitative\n",
    "# p : proportion entre apprentissage et test\n",
    "# methodes : liste des méthodes de discrimination\n",
    "# size : une grille des paramètres à optimiser\n",
    "# xinit : générateur de nombres aléatoires\n",
    "# N : nombre de réplications apprentissage/test\n",
    "# typerr : \"cv\" ou \"boo\" ou \"oob\"\n",
    "# number : nombre de répétitions CV ou bootstrap\n",
    "# pred : liste des matrices de prévision\n",
    "# type d’erreur\n",
    "Control=trainControl(method=typerr,number=number)\n",
    "# initialisation du générateur\n",
    "set.seed(xinit)\n",
    "# liste de matrices stockant les prévisions\n",
    "# une par méthode\n",
    "inTrain=createDataPartition(Y,p=p,list=FALSE)\n",
    "ntest=length(Y[-inTrain])\n",
    "pred=vector(\"list\",length(methodes))\n",
    "names(pred)=methodes\n",
    "pred=lapply(pred,function(x)x=matrix(0,\n",
    "nrow=ntest,ncol=N))\n",
    "obs=matrix(0,ntest,N)\n",
    "set.seed(xinit)\n",
    "for(i in 1:N) {\n",
    "# N itérations\n",
    "# indices de l’échantillon d’apprentissage\n",
    "inTrain=createDataPartition(Y,p=p,list=FALSE)\n",
    "# Extraction des échantillons\n",
    "trainDescr=X[inTrain,]\n",
    "testDescr=X[-inTrain,]\n",
    "trainY=Y[inTrain]\n",
    "testY=Y[-inTrain]\n",
    "# stockage des observés de testY\n",
    "obs[,i]=testY\n",
    "# centrage et réduction des variables\n",
    "xTrans=preProcess(trainDescr)\n",
    "trainDescr=predict(xTrans,trainDescr)\n",
    "testDescr=predict(xTrans,testDescr)\n",
    "# estimation et optimisation des modèles\n",
    "# pour chaque méthode de la liste\n",
    "for(j in 1:length(methodes)) {\n",
    "# modélisation\n",
    "modFit = train(trainDescr, trainY,method = methodes[j], tuneLength = size[j],\n",
    "               trControl = Control)\n",
    "# prévisions\n",
    "if (type==\"prob\")  pred[[j]][,i]=predict(modFit,\n",
    "newdata = testDescr,type=type)[,1]\n",
    "else pred[[j]][,i]=predict(modFit,\n",
    "newdata = testDescr)\n",
    "}}\n",
    "list(pred=pred,obs=obs)\n",
    "# résultats\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {
    "height": "630.933px",
    "left": "33px",
    "right": "1081.6px",
    "top": "107.133px",
    "width": "153px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
